{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM (Hidden Markov Models)\n",
    "\n",
    "#### TL; DR\n",
    "To develop a deeper understanding of HMM\n",
    "\n",
    "### Reference Material\n",
    "\n",
    "[lazyprogrammer Github](https://github.com/lazyprogrammer/machine_learning_examples/tree/master/hmm_class)\n",
    "\n",
    "[HMM_Udemy](https://www.udemy.com/unsupervised-machine-learning-hidden-markov-models-in-python/learn/v4/overview)\n",
    "\n",
    "### Math\n",
    "\n",
    "- Conditional Probabilities $P(s_{i}|s_{i-1})$\n",
    "\n",
    "Orders\n",
    "- 1st is only the previous state matters\n",
    "\n",
    "$$P(s_{i}|s_{i-1})$$\n",
    "\n",
    "- 2nd is the last 2 previous state matters \n",
    "\n",
    "$$P(s_{i}|s_{i-1},s_{i-2})$$\n",
    "\n",
    "- 3rd is...\n",
    "\n",
    "### Smoothing\n",
    "\n",
    "Basic idea: give things that have a value of 0 a small value\n",
    "\n",
    "satisfy the \"strictly positive\" requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T20:30:43.565688Z",
     "start_time": "2019-04-29T20:30:43.553704Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import string\n",
    "from future.utils import iteritems\n",
    "import sys\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MM Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T13:37:29.476987Z",
     "start_time": "2019-04-28T13:37:29.436952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-1</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   -1  8\n",
       "0   4  8\n",
       "1  -1  2\n",
       "2   1  B\n",
       "3  -1  5\n",
       "4   7  5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_data_df = pd.read_csv('./data/site_data.csv')\n",
    "print(len(site_data_df))\n",
    "site_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T13:40:26.957943Z",
     "start_time": "2019-04-28T13:40:26.955223Z"
    }
   },
   "outputs": [],
   "source": [
    "transitions = {}\n",
    "row_sums = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T13:42:58.021840Z",
     "start_time": "2019-04-28T13:42:57.897062Z"
    }
   },
   "outputs": [],
   "source": [
    "# collect counts\n",
    "for line in open('./data/site_data.csv'):\n",
    "    s, e = line.rstrip().split(',')\n",
    "    transitions[(s, e)] = transitions.get((s, e), 0.) + 1\n",
    "    row_sums[s] = row_sums.get(s, 0.) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T13:44:31.908468Z",
     "start_time": "2019-04-28T13:44:31.905131Z"
    }
   },
   "outputs": [],
   "source": [
    "# normalize\n",
    "for k, v in transitions.items():\n",
    "    s, e = k\n",
    "    transitions[k] = v / row_sums[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T13:49:54.319549Z",
     "start_time": "2019-04-28T13:49:54.313682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial start page 8: 0.10152591025834719\n",
      "initial start page 2: 0.09507982071813466\n",
      "initial start page 5: 0.09779926474291183\n",
      "initial start page 9: 0.10384247368686106\n",
      "initial start page 0: 0.10298635241980159\n",
      "initial start page 6: 0.09800070504104345\n",
      "initial start page 7: 0.09971294757516241\n",
      "initial start page 1: 0.10348995316513068\n",
      "initial start page 4: 0.10243239159993957\n",
      "initial start page 3: 0.09513018079266758\n"
     ]
    }
   ],
   "source": [
    "# initial state distributions\n",
    "# print(\"initial state distribution\")\n",
    "for k, v in transitions.items():\n",
    "    s, e = k\n",
    "    if s == '-1':\n",
    "        print(\"initial start page %s: %s\" % (e, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T13:48:19.580947Z",
     "start_time": "2019-04-28T13:48:19.575127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounce rate for 1: 0.125939617991374\n",
      "bounce rate for 2: 0.12649551345962112\n",
      "bounce rate for 8: 0.12529550827423167\n",
      "bounce rate for 6: 0.1208153180975911\n",
      "bounce rate for 7: 0.12371650388179314\n",
      "bounce rate for 3: 0.12743384922616077\n",
      "bounce rate for 4: 0.1255756067205974\n",
      "bounce rate for 5: 0.12369559684398065\n",
      "bounce rate for 0: 0.1279673590504451\n",
      "bounce rate for 9: 0.13176232104396302\n"
     ]
    }
   ],
   "source": [
    "# which page has the highest bounce?\n",
    "for k, v in transitions.items():\n",
    "    s, e = k\n",
    "    if e == 'B':\n",
    "        print(\"bounce rate for %s: %s\" % (s, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "\n",
    "- Page 9 has the highest start page\n",
    "- Page 9 has the highest bounce rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MM Using Text Analysis\n",
    "\n",
    "Predicting next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T15:32:11.218518Z",
     "start_time": "2019-04-28T15:32:11.215551Z"
    }
   },
   "outputs": [],
   "source": [
    "initial = {}\n",
    "second_word = {}\n",
    "transitions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T15:33:20.655179Z",
     "start_time": "2019-04-28T15:33:20.651115Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    return s.translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "def add2dict(d, k, v):\n",
    "    if k not in d:\n",
    "        d[k] = []\n",
    "    d[k].append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T15:33:21.211405Z",
     "start_time": "2019-04-28T15:33:21.169189Z"
    }
   },
   "outputs": [],
   "source": [
    "for line in open('./data/robert_frost.txt'):\n",
    "    tokens = remove_punctuation(line.rstrip().lower()).split()\n",
    "    \n",
    "    T = len(tokens)\n",
    "    for i in range(T):\n",
    "        t = tokens[i]\n",
    "        if i == 0:\n",
    "            initial[t] = initial.get(t, 0.) + 1\n",
    "        else:\n",
    "            t_1 = tokens[i-1]\n",
    "            if i == T-1:\n",
    "                add2dict(transitions, (t_1, t), 'END')\n",
    "            if i == 1:\n",
    "                add2dict(second_word, t_1, t)\n",
    "            else:\n",
    "                t_2 = tokens[i-2]\n",
    "                add2dict(transitions, (t_2, t_1), t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T15:45:39.768936Z",
     "start_time": "2019-04-28T15:45:39.765309Z"
    }
   },
   "outputs": [],
   "source": [
    "# normalize the initial\n",
    "initial_total = sum(initial.values())\n",
    "for t, c in initial.items():\n",
    "    initial[t] = c / initial_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T15:46:36.403419Z",
     "start_time": "2019-04-28T15:46:36.399127Z"
    }
   },
   "outputs": [],
   "source": [
    "def list2pdict(ts):\n",
    "    d = {}\n",
    "    n = len(ts)\n",
    "    for t in ts:\n",
    "        d[t] = d.get(t, 0.) + 1\n",
    "    for t, c in d.items():\n",
    "        d[t] = c / n\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T15:46:37.041613Z",
     "start_time": "2019-04-28T15:46:37.005596Z"
    }
   },
   "outputs": [],
   "source": [
    "for t_1, ts in second_word.items():\n",
    "    second_word[t_1] = list2pdict(ts)\n",
    "    \n",
    "for k, ts in transitions.items():\n",
    "    transitions[k] = list2pdict(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T15:47:40.596831Z",
     "start_time": "2019-04-28T15:47:40.586131Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_word(d):\n",
    "    p0 = np.random.random()\n",
    "    cumulative = 0\n",
    "    for t, p in d.items():\n",
    "        cumulative += p\n",
    "        if p0 < cumulative:\n",
    "            return t\n",
    "    assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T15:53:33.665231Z",
     "start_time": "2019-04-28T15:53:33.659596Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate():\n",
    "    for i in range(1):\n",
    "        sentence = []\n",
    "        \n",
    "        w0 = sample_word(initial)\n",
    "        sentence.append(w0)\n",
    "        \n",
    "        w1 = sample_word(second_word[w0])\n",
    "        sentence.append(w1)\n",
    "        \n",
    "        while True:\n",
    "            w2 = sample_word(transitions[w0, w1])\n",
    "            if w2 == 'END':\n",
    "                break\n",
    "            sentence.append(w2)\n",
    "            w0 = w1\n",
    "            w1 = w2\n",
    "        print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T15:53:34.337734Z",
     "start_time": "2019-04-28T15:53:34.333944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here loveless birds now flock as winter friends\n"
     ]
    }
   ],
   "source": [
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T15:50:59.705970Z",
     "start_time": "2019-04-28T15:50:59.700803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he guessed theyd know what a name should matter between us\n",
      "to set the voices speaking out of forty firkins\n",
      "dont build me a resurrected tree\n",
      "who wants to get at\n"
     ]
    }
   ],
   "source": [
    " generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T15:59:21.433862Z",
     "start_time": "2019-04-28T15:59:21.428050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'where': 0.02,\n",
       " 'watch': 0.04,\n",
       " 'stop': 0.02,\n",
       " 'ask': 0.02,\n",
       " 'say': 0.04,\n",
       " 'carry': 0.02,\n",
       " 'think': 0.02,\n",
       " 'make': 0.12,\n",
       " 'everything': 0.02,\n",
       " 'spare': 0.02,\n",
       " 'see': 0.1,\n",
       " 'turn': 0.02,\n",
       " 'undo': 0.02,\n",
       " 'let': 0.02,\n",
       " 'go': 0.02,\n",
       " 'shut': 0.02,\n",
       " 'bring': 0.02,\n",
       " 'entertain': 0.02,\n",
       " 'find': 0.02,\n",
       " 'send': 0.02,\n",
       " 'such': 0.02,\n",
       " 'wonder': 0.02,\n",
       " 'no': 0.02,\n",
       " 'tell': 0.02,\n",
       " 'stand': 0.02,\n",
       " 'reconnoitre': 0.02,\n",
       " 'set': 0.02,\n",
       " 'blow': 0.02,\n",
       " 'ridgely': 0.02,\n",
       " 'the': 0.04,\n",
       " 'curl': 0.02,\n",
       " 'call': 0.02,\n",
       " 'which': 0.02,\n",
       " 'be': 0.02,\n",
       " 'drag': 0.02,\n",
       " 'come': 0.02,\n",
       " 'live': 0.02,\n",
       " 'break': 0.02}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_word['to']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T16:00:13.742985Z",
     "start_time": "2019-04-28T16:00:13.659199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('two', 'roads'): {'diverged': 1.0},\n",
       " ('roads', 'diverged'): {'in': 1.0},\n",
       " ('diverged', 'in'): {'a': 1.0},\n",
       " ('in', 'a'): {'yellow': 0.07142857142857142,\n",
       "  'wood': 0.07142857142857142,\n",
       "  'window': 0.07142857142857142,\n",
       "  'packing': 0.07142857142857142,\n",
       "  'byroad': 0.07142857142857142,\n",
       "  'family': 0.07142857142857142,\n",
       "  'new': 0.07142857142857142,\n",
       "  'row': 0.07142857142857142,\n",
       "  'time': 0.07142857142857142,\n",
       "  'town': 0.07142857142857142,\n",
       "  'book': 0.07142857142857142,\n",
       "  'smother': 0.07142857142857142,\n",
       "  'glass': 0.14285714285714285},\n",
       " ('yellow', 'wood'): {'END': 1.0},\n",
       " ('a', 'yellow'): {'wood': 1.0},\n",
       " ('and', 'sorry'): {'i': 1.0},\n",
       " ('sorry', 'i'): {'could': 0.5, 'ever': 0.5},\n",
       " ('i', 'could'): {'not': 0.2, 'END': 0.2, 'have': 0.2, 'see': 0.3, 'do': 0.1},\n",
       " ('could', 'not'): {'travel': 0.5, 'say': 0.5},\n",
       " ('travel', 'both'): {'END': 1.0},\n",
       " ('not', 'travel'): {'both': 1.0},\n",
       " ('and', 'be'): {'one': 0.5, 'whole': 0.5},\n",
       " ('be', 'one'): {'traveler': 1.0},\n",
       " ('one', 'traveler'): {'long': 1.0},\n",
       " ('traveler', 'long'): {'i': 1.0},\n",
       " ('i', 'stood'): {'END': 1.0},\n",
       " ('long', 'i'): {'stood': 0.5, 'lay': 0.5},\n",
       " ('and', 'looked'): {'down': 1.0},\n",
       " ('looked', 'down'): {'one': 0.5, 'the': 0.5},\n",
       " ('down', 'one'): {'as': 0.5, 'street': 0.5},\n",
       " ('one', 'as'): {'far': 1.0},\n",
       " ('as', 'far'): {'as': 1.0},\n",
       " ('far', 'as'): {'i': 0.5, 'we': 0.5},\n",
       " ('as', 'i'): {'could': 0.25, 'am': 0.25, 'do': 0.25, 'say': 0.25},\n",
       " ('to', 'where'): {'it': 1.0},\n",
       " ('where', 'it'): {'bent': 0.16666666666666666,\n",
       "  'ended': 0.16666666666666666,\n",
       "  'fell': 0.16666666666666666,\n",
       "  'wants': 0.16666666666666666,\n",
       "  'came': 0.16666666666666666,\n",
       "  'is': 0.16666666666666666},\n",
       " ('it', 'bent'): {'in': 1.0},\n",
       " ('bent', 'in'): {'the': 1.0},\n",
       " ('the', 'undergrowth'): {'END': 1.0},\n",
       " ('in', 'the'): {'undergrowth': 0.021739130434782608,\n",
       "  'village': 0.021739130434782608,\n",
       "  'stars': 0.021739130434782608,\n",
       "  'confusion': 0.021739130434782608,\n",
       "  'excited': 0.021739130434782608,\n",
       "  'scene': 0.021739130434782608,\n",
       "  'river': 0.021739130434782608,\n",
       "  'cold': 0.043478260869565216,\n",
       "  'town': 0.021739130434782608,\n",
       "  'warrant': 0.021739130434782608,\n",
       "  'stable': 0.021739130434782608,\n",
       "  'huse': 0.021739130434782608,\n",
       "  'tail': 0.021739130434782608,\n",
       "  'dark': 0.043478260869565216,\n",
       "  'mountain': 0.021739130434782608,\n",
       "  'box': 0.021739130434782608,\n",
       "  'night': 0.021739130434782608,\n",
       "  'bedroom': 0.021739130434782608,\n",
       "  'cellar': 0.15217391304347827,\n",
       "  'joints': 0.021739130434782608,\n",
       "  'light': 0.021739130434782608,\n",
       "  'room': 0.021739130434782608,\n",
       "  'attic': 0.043478260869565216,\n",
       "  'grass': 0.021739130434782608,\n",
       "  'rain': 0.021739130434782608,\n",
       "  'sun': 0.021739130434782608,\n",
       "  'empty': 0.021739130434782608,\n",
       "  'open': 0.021739130434782608,\n",
       "  'kitchen': 0.021739130434782608,\n",
       "  'weather': 0.021739130434782608,\n",
       "  'playhouse': 0.021739130434782608,\n",
       "  'instep': 0.021739130434782608,\n",
       "  'newcut': 0.021739130434782608,\n",
       "  'plowed': 0.021739130434782608,\n",
       "  'bushy': 0.021739130434782608,\n",
       "  'heat': 0.021739130434782608,\n",
       "  'yard': 0.021739130434782608},\n",
       " ('then', 'took'): {'the': 1.0},\n",
       " ('took', 'the'): {'other': 0.25, 'one': 0.25, 'long': 0.25, 'hall': 0.25},\n",
       " ('the', 'other'): {'as': 1.0},\n",
       " ('other', 'as'): {'just': 1.0},\n",
       " ('as', 'just'): {'as': 1.0},\n",
       " ('as', 'fair'): {'END': 1.0},\n",
       " ('just', 'as'): {'fair': 0.2, 'fast': 0.4, 'empty': 0.2, 'well': 0.2},\n",
       " ('and', 'having'): {'perhaps': 1.0},\n",
       " ('having', 'perhaps'): {'the': 1.0},\n",
       " ('perhaps', 'the'): {'better': 1.0},\n",
       " ('better', 'claim'): {'END': 1.0},\n",
       " ('the', 'better'): {'claim': 1.0},\n",
       " ('because', 'it'): {'was': 1.0},\n",
       " ('it', 'was'): {'grassy': 0.07692307692307693,\n",
       "  'to': 0.07692307692307693,\n",
       "  'the': 0.15384615384615385,\n",
       "  'all': 0.07692307692307693,\n",
       "  'END': 0.07692307692307693,\n",
       "  'there': 0.07692307692307693,\n",
       "  'proclaimed': 0.07692307692307693,\n",
       "  'cut': 0.07692307692307693,\n",
       "  'raining': 0.07692307692307693,\n",
       "  'coming': 0.07692307692307693,\n",
       "  'long': 0.07692307692307693,\n",
       "  'bad': 0.07692307692307693},\n",
       " ('was', 'grassy'): {'and': 1.0},\n",
       " ('grassy', 'and'): {'wanted': 1.0},\n",
       " ('wanted', 'wear'): {'END': 1.0},\n",
       " ('and', 'wanted'): {'wear': 1.0},\n",
       " ('though', 'as'): {'for': 1.0},\n",
       " ('as', 'for'): {'that': 0.6666666666666666, 'the': 0.3333333333333333},\n",
       " ('for', 'that'): {'the': 0.3333333333333333, 'END': 0.6666666666666666},\n",
       " ('that', 'the'): {'passing': 0.5, 'brook': 0.5},\n",
       " ('passing', 'there'): {'END': 1.0},\n",
       " ('the', 'passing'): {'there': 1.0},\n",
       " ('had', 'worn'): {'them': 1.0},\n",
       " ('worn', 'them'): {'really': 1.0},\n",
       " ('them', 'really'): {'about': 1.0},\n",
       " ('really', 'about'): {'the': 1.0},\n",
       " ('the', 'same'): {'END': 0.5, 'and': 0.25, 'as': 0.25},\n",
       " ('about', 'the'): {'same': 0.3333333333333333,\n",
       "  'weather': 0.3333333333333333,\n",
       "  'birch': 0.3333333333333333},\n",
       " ('and', 'both'): {'that': 0.5, 'of': 0.5},\n",
       " ('both', 'that'): {'morning': 1.0},\n",
       " ('that', 'morning'): {'equally': 1.0},\n",
       " ('equally', 'lay'): {'END': 1.0},\n",
       " ('morning', 'equally'): {'lay': 1.0},\n",
       " ('in', 'leaves'): {'no': 1.0},\n",
       " ('leaves', 'no'): {'step': 1.0},\n",
       " ('no', 'step'): {'had': 1.0},\n",
       " ('step', 'had'): {'trodden': 1.0},\n",
       " ('trodden', 'black'): {'END': 1.0},\n",
       " ('had', 'trodden'): {'black': 1.0},\n",
       " ('oh', 'i'): {'kept': 1.0},\n",
       " ('i', 'kept'): {'the': 0.5, 'remembering': 0.5},\n",
       " ('kept', 'the'): {'first': 1.0},\n",
       " ('the', 'first'): {'for': 0.5, 'of': 0.5},\n",
       " ('first', 'for'): {'another': 1.0},\n",
       " ('another', 'day'): {'END': 1.0},\n",
       " ('for', 'another'): {'day': 0.5, 'door': 0.5},\n",
       " ('yet', 'knowing'): {'how': 1.0},\n",
       " ('knowing', 'how'): {'way': 1.0},\n",
       " ('how', 'way'): {'leads': 1.0},\n",
       " ('way', 'leads'): {'on': 1.0},\n",
       " ('leads', 'on'): {'to': 1.0},\n",
       " ('to', 'way'): {'END': 1.0},\n",
       " ('on', 'to'): {'way': 1.0},\n",
       " ('i', 'doubted'): {'if': 1.0},\n",
       " ('doubted', 'if'): {'i': 1.0},\n",
       " ('if', 'i'): {'should': 0.08333333333333333,\n",
       "  'though': 0.08333333333333333,\n",
       "  'END': 0.08333333333333333,\n",
       "  'was': 0.08333333333333333,\n",
       "  'remember': 0.08333333333333333,\n",
       "  'havent': 0.08333333333333333,\n",
       "  'ask': 0.08333333333333333,\n",
       "  'could': 0.25,\n",
       "  'err': 0.08333333333333333,\n",
       "  'were': 0.08333333333333333},\n",
       " ('i', 'should'): {'ever': 0.3333333333333333,\n",
       "  'say': 0.3333333333333333,\n",
       "  'feel': 0.3333333333333333},\n",
       " ('should', 'ever'): {'come': 1.0},\n",
       " ('come', 'back'): {'END': 0.2,\n",
       "  'from': 0.2,\n",
       "  'shes': 0.2,\n",
       "  'but': 0.2,\n",
       "  'its': 0.2},\n",
       " ('ever', 'come'): {'back': 1.0},\n",
       " ('i', 'shall'): {'be': 0.5, 'suspect': 0.5},\n",
       " ('shall', 'be'): {'telling': 1.0},\n",
       " ('be', 'telling'): {'this': 1.0},\n",
       " ('telling', 'this'): {'with': 1.0},\n",
       " ('this', 'with'): {'a': 1.0},\n",
       " ('a', 'sigh'): {'END': 1.0},\n",
       " ('with', 'a'): {'sigh': 0.16666666666666666,\n",
       "  'hornyhanded': 0.16666666666666666,\n",
       "  'mother': 0.16666666666666666,\n",
       "  'swish': 0.16666666666666666,\n",
       "  'buggy': 0.16666666666666666,\n",
       "  'man': 0.16666666666666666},\n",
       " ('somewhere', 'ages'): {'and': 1.0},\n",
       " ('ages', 'and'): {'ages': 1.0},\n",
       " ('ages', 'hence'): {'END': 1.0},\n",
       " ('and', 'ages'): {'hence': 1.0},\n",
       " ('a', 'wood'): {'and': 1.0},\n",
       " ('and', 'i'): {'END': 0.18181818181818182,\n",
       "  'can': 0.09090909090909091,\n",
       "  'dont': 0.09090909090909091,\n",
       "  'read': 0.09090909090909091,\n",
       "  'know': 0.09090909090909091,\n",
       "  'dread': 0.09090909090909091,\n",
       "  'thought': 0.09090909090909091,\n",
       "  'only': 0.09090909090909091,\n",
       "  'have': 0.09090909090909091,\n",
       "  'get': 0.09090909090909091},\n",
       " ('wood', 'and'): {'i': 1.0},\n",
       " ('i', 'took'): {'the': 0.5, 'him': 0.5},\n",
       " ('the', 'one'): {'less': 0.2,\n",
       "  'they': 0.2,\n",
       "  'bearing': 0.2,\n",
       "  'END': 0.2,\n",
       "  'you': 0.2},\n",
       " ('one', 'less'): {'traveled': 1.0},\n",
       " ('traveled', 'by'): {'END': 1.0},\n",
       " ('less', 'traveled'): {'by': 1.0},\n",
       " ('and', 'that'): {'has': 0.5, 'was': 0.5},\n",
       " ('that', 'has'): {'made': 1.0},\n",
       " ('has', 'made'): {'all': 0.5, 'him': 0.5},\n",
       " ('made', 'all'): {'the': 1.0},\n",
       " ('the', 'difference'): {'END': 1.0},\n",
       " ('all', 'the'): {'difference': 0.07142857142857142,\n",
       "  'soulandbody': 0.07142857142857142,\n",
       "  'rain': 0.07142857142857142,\n",
       "  'burden': 0.07142857142857142,\n",
       "  'way': 0.07142857142857142,\n",
       "  'talking': 0.07142857142857142,\n",
       "  'family': 0.07142857142857142,\n",
       "  'houses': 0.07142857142857142,\n",
       "  'day': 0.07142857142857142,\n",
       "  'flowers': 0.07142857142857142,\n",
       "  'same': 0.07142857142857142,\n",
       "  'worse': 0.14285714285714285,\n",
       "  'money': 0.07142857142857142},\n",
       " ('whose', 'woods'): {'these': 1.0},\n",
       " ('woods', 'these'): {'are': 1.0},\n",
       " ('these', 'are'): {'i': 1.0},\n",
       " ('are', 'i'): {'think': 1.0},\n",
       " ('i', 'think'): {'i': 0.2857142857142857,\n",
       "  'END': 0.14285714285714285,\n",
       "  'its': 0.14285714285714285,\n",
       "  'were': 0.14285714285714285,\n",
       "  'he': 0.14285714285714285,\n",
       "  'ill': 0.14285714285714285},\n",
       " ('i', 'know'): {'END': 0.25,\n",
       "  'enough': 0.125,\n",
       "  'of': 0.25,\n",
       "  'and': 0.125,\n",
       "  'what': 0.125,\n",
       "  'the': 0.125},\n",
       " ('think', 'i'): {'know': 1.0},\n",
       " ('his', 'house'): {'is': 0.5, 'when': 0.5},\n",
       " ('house', 'is'): {'in': 1.0},\n",
       " ('is', 'in'): {'the': 1.0},\n",
       " ('village', 'though'): {'END': 1.0},\n",
       " ('the', 'village'): {'though': 1.0},\n",
       " ('he', 'will'): {'not': 0.5, 'do': 0.5},\n",
       " ('will', 'not'): {'see': 1.0},\n",
       " ('not', 'see'): {'me': 1.0},\n",
       " ('see', 'me'): {'stopping': 0.5, 'end': 0.5},\n",
       " ('stopping', 'here'): {'END': 1.0},\n",
       " ('me', 'stopping'): {'here': 1.0},\n",
       " ('to', 'watch'): {'his': 0.5, 'me': 0.5},\n",
       " ('watch', 'his'): {'woods': 1.0},\n",
       " ('his', 'woods'): {'fill': 1.0},\n",
       " ('woods', 'fill'): {'up': 1.0},\n",
       " ('fill', 'up'): {'with': 1.0},\n",
       " ('with', 'snow'): {'END': 1.0},\n",
       " ('up', 'with'): {'snow': 0.3333333333333333,\n",
       "  'END': 0.3333333333333333,\n",
       "  'sawdust': 0.3333333333333333},\n",
       " ('my', 'little'): {'horse': 1.0},\n",
       " ('little', 'horse'): {'must': 1.0},\n",
       " ('horse', 'must'): {'think': 1.0},\n",
       " ('must', 'think'): {'it': 1.0},\n",
       " ('it', 'queer'): {'END': 1.0},\n",
       " ('think', 'it'): {'queer': 0.5, 'isnt': 0.5},\n",
       " ('to', 'stop'): {'without': 0.3333333333333333,\n",
       "  'the': 0.3333333333333333,\n",
       "  'and': 0.3333333333333333},\n",
       " ('stop', 'without'): {'a': 1.0},\n",
       " ('without', 'a'): {'farmhouse': 0.3333333333333333,\n",
       "  'jerk': 0.3333333333333333,\n",
       "  'breath': 0.3333333333333333},\n",
       " ('farmhouse', 'near'): {'END': 1.0},\n",
       " ('a', 'farmhouse'): {'near': 1.0},\n",
       " ('between', 'the'): {'woods': 0.5, 'house': 0.5},\n",
       " ('the', 'woods'): {'and': 0.3333333333333333,\n",
       "  'are': 0.3333333333333333,\n",
       "  'excitement': 0.3333333333333333},\n",
       " ('woods', 'and'): {'frozen': 1.0},\n",
       " ('frozen', 'lake'): {'END': 1.0},\n",
       " ('and', 'frozen'): {'lake': 1.0},\n",
       " ('the', 'darkest'): {'evening': 1.0},\n",
       " ('darkest', 'evening'): {'of': 1.0},\n",
       " ('evening', 'of'): {'the': 1.0},\n",
       " ('the', 'year'): {'END': 1.0},\n",
       " ('of', 'the'): {'year': 0.03333333333333333,\n",
       "  'last': 0.03333333333333333,\n",
       "  'sun': 0.06666666666666667,\n",
       "  'swarm': 0.03333333333333333,\n",
       "  'grange': 0.03333333333333333,\n",
       "  'times': 0.03333333333333333,\n",
       "  'expense': 0.03333333333333333,\n",
       "  'night': 0.03333333333333333,\n",
       "  'world': 0.03333333333333333,\n",
       "  'great': 0.03333333333333333,\n",
       "  'door': 0.03333333333333333,\n",
       "  'grave': 0.03333333333333333,\n",
       "  'bed': 0.06666666666666667,\n",
       "  'name': 0.03333333333333333,\n",
       "  'one': 0.03333333333333333,\n",
       "  'family': 0.03333333333333333,\n",
       "  'stark': 0.03333333333333333,\n",
       "  'salt': 0.03333333333333333,\n",
       "  'old': 0.06666666666666667,\n",
       "  'train': 0.03333333333333333,\n",
       "  'adventure': 0.03333333333333333,\n",
       "  'children': 0.03333333333333333,\n",
       "  'house': 0.03333333333333333,\n",
       "  'tower': 0.03333333333333333,\n",
       "  'lettered': 0.03333333333333333,\n",
       "  'outdoor': 0.03333333333333333,\n",
       "  'wet': 0.03333333333333333},\n",
       " ('he', 'gives'): {'his': 1.0},\n",
       " ('gives', 'his'): {'harness': 1.0},\n",
       " ('his', 'harness'): {'bells': 1.0},\n",
       " ('harness', 'bells'): {'a': 1.0},\n",
       " ('a', 'shake'): {'END': 1.0},\n",
       " ('bells', 'a'): {'shake': 1.0},\n",
       " ('to', 'ask'): {'if': 1.0},\n",
       " ('ask', 'if'): {'there': 1.0},\n",
       " ('if', 'there'): {'is': 0.5, 'had': 0.5},\n",
       " ('there', 'is'): {'some': 0.25, 'a': 0.25, 'is': 0.25, 'our': 0.25},\n",
       " ('some', 'mistake'): {'END': 1.0},\n",
       " ('is', 'some'): {'mistake': 1.0},\n",
       " ('the', 'only'): {'other': 0.16666666666666666,\n",
       "  'times': 0.16666666666666666,\n",
       "  'fault': 0.16666666666666666,\n",
       "  'finished': 0.16666666666666666,\n",
       "  'house': 0.16666666666666666,\n",
       "  'field': 0.16666666666666666},\n",
       " ('only', 'other'): {'sounds': 1.0},\n",
       " ('other', 'sounds'): {'the': 1.0},\n",
       " ('the', 'sweep'): {'END': 1.0},\n",
       " ('sounds', 'the'): {'sweep': 1.0},\n",
       " ('of', 'easy'): {'wind': 1.0},\n",
       " ('easy', 'wind'): {'and': 1.0},\n",
       " ('wind', 'and'): {'downy': 0.5, 'opening': 0.5},\n",
       " ('downy', 'flake'): {'END': 1.0},\n",
       " ('and', 'downy'): {'flake': 1.0},\n",
       " ('woods', 'are'): {'lovely': 1.0},\n",
       " ('are', 'lovely'): {'dark': 1.0},\n",
       " ('lovely', 'dark'): {'and': 1.0},\n",
       " ('and', 'deep'): {'END': 1.0},\n",
       " ('dark', 'and'): {'deep': 0.5, 'its': 0.5},\n",
       " ('but', 'i'): {'have': 0.1,\n",
       "  'mistrusted': 0.1,\n",
       "  'can': 0.1,\n",
       "  'own': 0.1,\n",
       "  'must': 0.1,\n",
       "  'never': 0.1,\n",
       "  'dont': 0.1,\n",
       "  'had': 0.1,\n",
       "  'didnt': 0.1,\n",
       "  'got': 0.1},\n",
       " ('i', 'have'): {'promises': 0.09090909090909091,\n",
       "  'been': 0.18181818181818182,\n",
       "  'walked': 0.09090909090909091,\n",
       "  'outwalked': 0.09090909090909091,\n",
       "  'looked': 0.09090909090909091,\n",
       "  'passed': 0.09090909090909091,\n",
       "  'stood': 0.09090909090909091,\n",
       "  'no': 0.09090909090909091,\n",
       "  'kept': 0.09090909090909091,\n",
       "  'filled': 0.09090909090909091},\n",
       " ('have', 'promises'): {'to': 1.0},\n",
       " ('to', 'keep'): {'END': 0.4, 'the': 0.4, 'accounts': 0.2},\n",
       " ('promises', 'to'): {'keep': 1.0},\n",
       " ('and', 'miles'): {'to': 1.0},\n",
       " ('miles', 'to'): {'go': 1.0},\n",
       " ('to', 'go'): {'before': 0.4, 'by': 0.2, 'west': 0.2, 'END': 0.2},\n",
       " ('go', 'before'): {'i': 1.0},\n",
       " ('i', 'sleep'): {'END': 1.0},\n",
       " ('before', 'i'): {'sleep': 0.4, 'went': 0.2, 'got': 0.2, 'can': 0.2},\n",
       " ('some', 'say'): {'the': 0.5, 'in': 0.5},\n",
       " ('say', 'the'): {'world': 0.5, 'word': 0.5},\n",
       " ('the', 'world'): {'will': 0.25, 'and': 0.5, 'END': 0.25},\n",
       " ('world', 'will'): {'end': 1.0},\n",
       " ('will', 'end'): {'in': 1.0},\n",
       " ('in', 'fire'): {'END': 1.0},\n",
       " ('end', 'in'): {'fire': 1.0},\n",
       " ('in', 'ice'): {'END': 1.0},\n",
       " ('say', 'in'): {'ice': 1.0},\n",
       " ('from', 'what'): {'ive': 1.0},\n",
       " ('what', 'ive'): {'tasted': 0.5, 'come': 0.5},\n",
       " ('ive', 'tasted'): {'of': 1.0},\n",
       " ('of', 'desire'): {'END': 1.0},\n",
       " ('tasted', 'of'): {'desire': 1.0},\n",
       " ('i', 'hold'): {'with': 1.0},\n",
       " ('hold', 'with'): {'those': 1.0},\n",
       " ('with', 'those'): {'who': 1.0},\n",
       " ('those', 'who'): {'favor': 1.0},\n",
       " ('favor', 'fire'): {'END': 1.0},\n",
       " ('who', 'favor'): {'fire': 1.0},\n",
       " ('but', 'if'): {'it': 0.3333333333333333,\n",
       "  'i': 0.3333333333333333,\n",
       "  'we': 0.3333333333333333},\n",
       " ('if', 'it'): {'had': 0.2,\n",
       "  'takes': 0.2,\n",
       "  'rains': 0.2,\n",
       "  'should': 0.2,\n",
       "  'was': 0.2},\n",
       " ('it', 'had'): {'to': 0.3333333333333333,\n",
       "  'sprung': 0.3333333333333333,\n",
       "  'its': 0.3333333333333333},\n",
       " ('had', 'to'): {'perish': 0.2,\n",
       "  'put': 0.2,\n",
       "  'own': 0.2,\n",
       "  'stop': 0.2,\n",
       "  'come': 0.2},\n",
       " ('perish', 'twice'): {'END': 1.0},\n",
       " ('to', 'perish'): {'twice': 1.0},\n",
       " ('know', 'enough'): {'of': 1.0},\n",
       " ('of', 'hate'): {'END': 1.0},\n",
       " ('enough', 'of'): {'hate': 1.0},\n",
       " ('to', 'say'): {'that': 0.125,\n",
       "  'END': 0.5,\n",
       "  'you': 0.125,\n",
       "  'the': 0.125,\n",
       "  'which': 0.125},\n",
       " ('say', 'that'): {'for': 0.6666666666666666, 'on': 0.3333333333333333},\n",
       " ('that', 'for'): {'destruction': 0.5, 'him': 0.5},\n",
       " ('destruction', 'ice'): {'END': 1.0},\n",
       " ('for', 'destruction'): {'ice': 1.0},\n",
       " ('also', 'great'): {'END': 1.0},\n",
       " ('is', 'also'): {'great': 1.0},\n",
       " ('would', 'suffice'): {'END': 1.0},\n",
       " ('and', 'would'): {'suffice': 1.0},\n",
       " ('natures', 'first'): {'green': 1.0},\n",
       " ('first', 'green'): {'is': 1.0},\n",
       " ('is', 'gold'): {'END': 1.0},\n",
       " ('green', 'is'): {'gold': 1.0},\n",
       " ('her', 'hardest'): {'hue': 1.0},\n",
       " ('hardest', 'hue'): {'to': 1.0},\n",
       " ('to', 'hold'): {'END': 1.0},\n",
       " ('hue', 'to'): {'hold': 1.0},\n",
       " ('her', 'early'): {'leafs': 1.0},\n",
       " ('early', 'leafs'): {'a': 1.0},\n",
       " ('a', 'flower'): {'END': 1.0},\n",
       " ('leafs', 'a'): {'flower': 1.0},\n",
       " ('but', 'only'): {'so': 0.5, 'a': 0.5},\n",
       " ('only', 'so'): {'an': 1.0},\n",
       " ('an', 'hour'): {'END': 0.3333333333333333, 'of': 0.6666666666666666},\n",
       " ('so', 'an'): {'hour': 1.0},\n",
       " ('then', 'leaf'): {'subsides': 1.0},\n",
       " ('leaf', 'subsides'): {'to': 1.0},\n",
       " ('to', 'leaf'): {'END': 1.0},\n",
       " ('subsides', 'to'): {'leaf': 1.0},\n",
       " ('so', 'eden'): {'sank': 1.0},\n",
       " ('eden', 'sank'): {'to': 1.0},\n",
       " ('to', 'grief'): {'END': 1.0},\n",
       " ('sank', 'to'): {'grief': 1.0},\n",
       " ('so', 'dawn'): {'goes': 1.0},\n",
       " ('dawn', 'goes'): {'down': 1.0},\n",
       " ('goes', 'down'): {'to': 1.0},\n",
       " ('to', 'day'): {'END': 1.0},\n",
       " ('down', 'to'): {'day': 0.5, 'walk': 0.5},\n",
       " ('nothing', 'gold'): {'can': 1.0},\n",
       " ('can', 'stay'): {'END': 1.0},\n",
       " ('gold', 'can'): {'stay': 1.0},\n",
       " ('have', 'been'): {'one': 0.3333333333333333,\n",
       "  'the': 0.16666666666666666,\n",
       "  'all': 0.16666666666666666,\n",
       "  'starks': 0.16666666666666666,\n",
       "  'a': 0.16666666666666666},\n",
       " ('been', 'one'): {'acquainted': 0.6666666666666666,\n",
       "  'stir': 0.3333333333333333},\n",
       " ('one', 'acquainted'): {'with': 1.0},\n",
       " ('acquainted', 'with'): {'the': 1.0},\n",
       " ('the', 'night'): {'END': 0.5714285714285714,\n",
       "  'outdoors': 0.14285714285714285,\n",
       "  'for': 0.14285714285714285,\n",
       "  'the': 0.14285714285714285},\n",
       " ('with', 'the'): {'night': 0.16666666666666666,\n",
       "  'heavy': 0.08333333333333333,\n",
       "  'desert': 0.08333333333333333,\n",
       "  'dead': 0.08333333333333333,\n",
       "  'branch': 0.08333333333333333,\n",
       "  'noise': 0.08333333333333333,\n",
       "  'odor': 0.08333333333333333,\n",
       "  'hiss': 0.08333333333333333,\n",
       "  'furthest': 0.08333333333333333,\n",
       "  'brook': 0.08333333333333333,\n",
       "  'farm': 0.08333333333333333},\n",
       " ('have', 'walked'): {'out': 1.0},\n",
       " ('walked', 'out'): {'in': 1.0},\n",
       " ('out', 'in'): {'rain': 0.25, 'his': 0.25, 'her': 0.25, 'the': 0.25},\n",
       " ('in', 'rain'): {'and': 0.14285714285714285,\n",
       "  'END': 0.5714285714285714,\n",
       "  'sometime': 0.14285714285714285,\n",
       "  'tomorrow': 0.14285714285714285},\n",
       " ('rain', 'and'): {'back': 0.5, 'snow': 0.5},\n",
       " ('and', 'back'): {'in': 1.0},\n",
       " ('back', 'in'): {'rain': 0.5, 'a': 0.5},\n",
       " ('have', 'outwalked'): {'the': 1.0},\n",
       " ('outwalked', 'the'): {'furthest': 1.0},\n",
       " ('the', 'furthest'): {'city': 0.5, 'bodies': 0.5},\n",
       " ('city', 'light'): {'END': 1.0},\n",
       " ('furthest', 'city'): {'light': 1.0},\n",
       " ('have', 'looked'): {'down': 0.5, 'as': 0.5},\n",
       " ('down', 'the'): {'saddest': 0.5, 'stairs': 0.5},\n",
       " ('the', 'saddest'): {'city': 1.0},\n",
       " ('city', 'lane'): {'END': 1.0},\n",
       " ('saddest', 'city'): {'lane': 1.0},\n",
       " ('have', 'passed'): {'by': 0.5, 'each': 0.5},\n",
       " ('passed', 'by'): {'the': 1.0},\n",
       " ('by', 'the'): {'watchman': 0.16666666666666666,\n",
       "  'tail': 0.16666666666666666,\n",
       "  'coat': 0.16666666666666666,\n",
       "  'voices': 0.16666666666666666,\n",
       "  'loss': 0.16666666666666666,\n",
       "  'legs': 0.16666666666666666},\n",
       " ('the', 'watchman'): {'on': 1.0},\n",
       " ('watchman', 'on'): {'his': 1.0},\n",
       " ('his', 'beat'): {'END': 1.0},\n",
       " ('on', 'his'): {'beat': 0.3333333333333333,\n",
       "  'feet': 0.3333333333333333,\n",
       "  'own': 0.3333333333333333},\n",
       " ('and', 'dropped'): {'my': 1.0},\n",
       " ('dropped', 'my'): {'eyes': 1.0},\n",
       " ('my', 'eyes'): {'unwilling': 1.0},\n",
       " ('eyes', 'unwilling'): {'to': 1.0},\n",
       " ('to', 'explain'): {'END': 1.0},\n",
       " ('unwilling', 'to'): {'explain': 1.0},\n",
       " ('have', 'stood'): {'still': 1.0},\n",
       " ('stood', 'still'): {'and': 1.0},\n",
       " ('still', 'and'): {'stopped': 1.0},\n",
       " ('and', 'stopped'): {'the': 1.0},\n",
       " ('stopped', 'the'): {'sound': 1.0},\n",
       " ('the', 'sound'): {'of': 1.0},\n",
       " ('of', 'feet'): {'END': 1.0},\n",
       " ('sound', 'of'): {'feet': 0.3333333333333333,\n",
       "  'which': 0.3333333333333333,\n",
       "  'a': 0.3333333333333333},\n",
       " ('when', 'far'): {'away': 1.0},\n",
       " ('far', 'away'): {'an': 0.5, 'END': 0.5},\n",
       " ('away', 'an'): {'interrupted': 1.0},\n",
       " ('interrupted', 'cry'): {'END': 1.0},\n",
       " ('an', 'interrupted'): {'cry': 1.0},\n",
       " ('came', 'over'): {'houses': 1.0},\n",
       " ('over', 'houses'): {'from': 1.0},\n",
       " ('houses', 'from'): {'another': 1.0},\n",
       " ('another', 'street'): {'END': 1.0},\n",
       " ('from', 'another'): {'street': 1.0},\n",
       " ('but', 'not'): {'to': 0.3333333333333333,\n",
       "  'come': 0.3333333333333333,\n",
       "  'unhouse': 0.3333333333333333},\n",
       " ('not', 'to'): {'call': 0.16666666666666666,\n",
       "  'blanket': 0.16666666666666666,\n",
       "  'be': 0.16666666666666666,\n",
       "  'care': 0.16666666666666666,\n",
       "  'sink': 0.16666666666666666,\n",
       "  'stand': 0.16666666666666666},\n",
       " ('to', 'call'): {'me': 0.5, 'it': 0.5},\n",
       " ('call', 'me'): {'back': 1.0},\n",
       " ('me', 'back'): {'or': 1.0},\n",
       " ('back', 'or'): {'say': 1.0},\n",
       " ('say', 'goodbye'): {'END': 0.5, 'in': 0.5},\n",
       " ('or', 'say'): {'goodbye': 1.0},\n",
       " ('and', 'further'): {'still': 1.0},\n",
       " ('further', 'still'): {'at': 1.0},\n",
       " ('still', 'at'): {'an': 1.0},\n",
       " ('at', 'an'): {'unearthly': 1.0},\n",
       " ('unearthly', 'height'): {'END': 1.0},\n",
       " ('an', 'unearthly'): {'height': 1.0},\n",
       " ('one', 'luminary'): {'clock': 1.0},\n",
       " ('luminary', 'clock'): {'against': 1.0},\n",
       " ('clock', 'against'): {'the': 1.0},\n",
       " ('the', 'sky'): {'END': 1.0},\n",
       " ('against', 'the'): {'sky': 0.2,\n",
       "  'blue': 0.2,\n",
       "  'attic': 0.2,\n",
       "  'arctic': 0.2,\n",
       "  'closing': 0.2},\n",
       " ('proclaimed', 'the'): {'time': 1.0},\n",
       " ('the', 'time'): {'was': 0.2,\n",
       "  'they': 0.2,\n",
       "  'being': 0.2,\n",
       "  'had': 0.2,\n",
       "  'away': 0.2},\n",
       " ('time', 'was'): {'neither': 1.0},\n",
       " ('was', 'neither'): {'wrong': 1.0},\n",
       " ('neither', 'wrong'): {'nor': 1.0},\n",
       " ('nor', 'right'): {'END': 1.0},\n",
       " ('wrong', 'nor'): {'right': 1.0},\n",
       " ('when', 'i'): {'go': 0.1,\n",
       "  'come': 0.1,\n",
       "  'looked': 0.1,\n",
       "  'can': 0.1,\n",
       "  'was': 0.2,\n",
       "  'asked': 0.1,\n",
       "  'heard': 0.1,\n",
       "  'passed': 0.1,\n",
       "  'lean': 0.1},\n",
       " ('i', 'go'): {'up': 1.0},\n",
       " ('go', 'up'): {'through': 1.0},\n",
       " ('up', 'through'): {'the': 1.0},\n",
       " ('through', 'the'): {'mowing': 0.3333333333333333,\n",
       "  'law': 0.3333333333333333,\n",
       "  'door': 0.3333333333333333},\n",
       " ('mowing', 'field'): {'END': 1.0},\n",
       " ('the', 'mowing'): {'field': 1.0},\n",
       " ('headless', 'aftermath'): {'END': 1.0},\n",
       " ('the', 'headless'): {'aftermath': 1.0},\n",
       " ('smoothlaid', 'like'): {'thatch': 1.0},\n",
       " ('like', 'thatch'): {'with': 1.0},\n",
       " ('thatch', 'with'): {'the': 1.0},\n",
       " ('heavy', 'dew'): {'END': 1.0},\n",
       " ('the', 'heavy'): {'dew': 1.0},\n",
       " ('half', 'closes'): {'the': 1.0},\n",
       " ('closes', 'the'): {'garden': 1.0},\n",
       " ('garden', 'path'): {'END': 1.0},\n",
       " ('the', 'garden'): {'path': 0.5, 'ground': 0.5},\n",
       " ('and', 'when'): {'i': 0.3333333333333333,\n",
       "  'alls': 0.3333333333333333,\n",
       "  'ive': 0.3333333333333333},\n",
       " ('i', 'come'): {'to': 1.0},\n",
       " ('come', 'to'): {'the': 0.25, 'END': 0.5, 'his': 0.25},\n",
       " ('to', 'the'): {'garden': 0.06666666666666667,\n",
       "  'fountain': 0.06666666666666667,\n",
       "  'famous': 0.06666666666666667,\n",
       "  'people': 0.06666666666666667,\n",
       "  'kitchen': 0.06666666666666667,\n",
       "  'bedroom': 0.06666666666666667,\n",
       "  'attic': 0.06666666666666667,\n",
       "  'knob': 0.06666666666666667,\n",
       "  'cellar': 0.06666666666666667,\n",
       "  'only': 0.06666666666666667,\n",
       "  'door': 0.06666666666666667,\n",
       "  'place': 0.06666666666666667,\n",
       "  'pianos': 0.06666666666666667,\n",
       "  'eye': 0.06666666666666667,\n",
       "  'root': 0.06666666666666667},\n",
       " ('garden', 'ground'): {'END': 1.0},\n",
       " ('the', 'whir'): {'of': 1.0},\n",
       " ('whir', 'of'): {'sober': 1.0},\n",
       " ('sober', 'birds'): {'END': 1.0},\n",
       " ('of', 'sober'): {'birds': 1.0},\n",
       " ('up', 'from'): {'the': 1.0},\n",
       " ('from', 'the'): {'tangle': 0.07142857142857142,\n",
       "  'high': 0.07142857142857142,\n",
       "  'house': 0.07142857142857142,\n",
       "  'cellar': 0.07142857142857142,\n",
       "  'kitchen': 0.07142857142857142,\n",
       "  'bedroom': 0.07142857142857142,\n",
       "  'slap': 0.07142857142857142,\n",
       "  'hall': 0.07142857142857142,\n",
       "  'rain': 0.07142857142857142,\n",
       "  'sense': 0.07142857142857142,\n",
       "  'ground': 0.14285714285714285,\n",
       "  'childrens': 0.07142857142857142,\n",
       "  'recent': 0.07142857142857142},\n",
       " ('the', 'tangle'): {'of': 1.0},\n",
       " ('tangle', 'of'): {'withered': 1.0},\n",
       " ('withered', 'weeds'): {'END': 1.0},\n",
       " ('of', 'withered'): {'weeds': 1.0},\n",
       " ('is', 'sadder'): {'than': 1.0},\n",
       " ('sadder', 'than'): {'any': 1.0},\n",
       " ('any', 'words'): {'END': 1.0},\n",
       " ('than', 'any'): {'words': 1.0},\n",
       " ('a', 'tree'): {'beside': 0.5, 'that': 0.5},\n",
       " ('tree', 'beside'): {'the': 1.0},\n",
       " ('beside', 'the'): {'wall': 0.5, 'track': 0.5},\n",
       " ('the', 'wall'): {'stands': 1.0},\n",
       " ('stands', 'bare'): {'END': 1.0},\n",
       " ('wall', 'stands'): {'bare': 1.0},\n",
       " ('but', 'a'): {'leaf': 0.5, 'house': 0.5},\n",
       " ('a', 'leaf'): {'that': 0.5, 'if': 0.5},\n",
       " ('leaf', 'that'): {'lingered': 1.0},\n",
       " ('lingered', 'brown'): {'END': 1.0},\n",
       " ('that', 'lingered'): {'brown': 1.0},\n",
       " ('disturbed', 'i'): {'doubt': 1.0},\n",
       " ('i', 'doubt'): {'not': 1.0},\n",
       " ('doubt', 'not'): {'by': 1.0},\n",
       " ('not', 'by'): {'my': 1.0},\n",
       " ('my', 'thought'): {'END': 1.0},\n",
       " ('by', 'my'): {'thought': 1.0},\n",
       " ('comes', 'softly'): {'rattling': 1.0},\n",
       " ('rattling', 'down'): {'END': 1.0},\n",
       " ('softly', 'rattling'): {'down': 1.0},\n",
       " ('i', 'end'): {'not': 1.0},\n",
       " ('end', 'not'): {'far': 1.0},\n",
       " ('not', 'far'): {'from': 0.3333333333333333,\n",
       "  'away': 0.3333333333333333,\n",
       "  'off': 0.3333333333333333},\n",
       " ('far', 'from'): {'my': 1.0},\n",
       " ('from', 'my'): {'going': 0.5, 'advantage': 0.5},\n",
       " ('going', 'forth'): {'END': 1.0},\n",
       " ('my', 'going'): {'forth': 1.0},\n",
       " ('by', 'picking'): {'the': 1.0},\n",
       " ('picking', 'the'): {'faded': 1.0},\n",
       " ('faded', 'blue'): {'END': 1.0},\n",
       " ('the', 'faded'): {'blue': 1.0},\n",
       " ('the', 'last'): {'remaining': 0.5, 'of': 0.5},\n",
       " ('last', 'remaining'): {'aster': 1.0},\n",
       " ('aster', 'flower'): {'END': 1.0},\n",
       " ('remaining', 'aster'): {'flower': 1.0},\n",
       " ('to', 'carry'): {'again': 1.0},\n",
       " ('carry', 'again'): {'to': 1.0},\n",
       " ('to', 'you'): {'END': 0.25, 'it': 0.25, 'to': 0.25, 'old': 0.25},\n",
       " ('again', 'to'): {'you': 1.0},\n",
       " ('a', 'voice'): {'said': 1.0},\n",
       " ('voice', 'said'): {'look': 1.0},\n",
       " ('said', 'look'): {'me': 1.0},\n",
       " ('look', 'me'): {'in': 1.0},\n",
       " ('me', 'in'): {'the': 1.0},\n",
       " ('the', 'stars'): {'END': 1.0},\n",
       " ('and', 'tell'): {'me': 0.75, 'him': 0.25},\n",
       " ('tell', 'me'): {'truly': 0.2,\n",
       "  'where': 0.2,\n",
       "  'why': 0.2,\n",
       "  'about': 0.2,\n",
       "  'whether': 0.2},\n",
       " ('me', 'truly'): {'men': 1.0},\n",
       " ('truly', 'men'): {'of': 1.0},\n",
       " ('of', 'earth'): {'END': 1.0},\n",
       " ('men', 'of'): {'earth': 1.0},\n",
       " ('if', 'all'): {'the': 1.0},\n",
       " ('soulandbody', 'scars'): {'END': 1.0},\n",
       " ('the', 'soulandbody'): {'scars': 1.0},\n",
       " ('were', 'not'): {'too': 0.25,\n",
       "  'thrown': 0.25,\n",
       "  'their': 0.25,\n",
       "  'allowed': 0.25},\n",
       " ('not', 'too'): {'much': 1.0},\n",
       " ('too', 'much'): {'to': 0.16666666666666666,\n",
       "  'for': 0.5,\n",
       "  'END': 0.16666666666666666,\n",
       "  'of': 0.16666666666666666},\n",
       " ('much', 'to'): {'pay': 0.3333333333333333,\n",
       "  'sell': 0.3333333333333333,\n",
       "  'keep': 0.3333333333333333},\n",
       " ('to', 'pay'): {'for': 1.0},\n",
       " ('for', 'birth'): {'END': 1.0},\n",
       " ('pay', 'for'): {'birth': 1.0},\n",
       " ('to', 'think'): {'to': 0.25, 'of': 0.75},\n",
       " ('think', 'to'): {'know': 1.0},\n",
       " ('to', 'know'): {'the': 0.3333333333333333, 'END': 0.6666666666666666},\n",
       " ('know', 'the'): {'country': 0.3333333333333333,\n",
       "  'valley': 0.3333333333333333,\n",
       "  'way': 0.3333333333333333},\n",
       " ('the', 'country'): {'and': 1.0},\n",
       " ('country', 'and'): {'now': 1.0},\n",
       " ('now', 'know'): {'END': 1.0},\n",
       " ('and', 'now'): {'know': 0.5, 'the': 0.5},\n",
       " ('the', 'hillside'): {'on': 1.0},\n",
       " ('hillside', 'on'): {'the': 1.0},\n",
       " ('on', 'the'): {'day': 0.047619047619047616,\n",
       "  'floor': 0.23809523809523808,\n",
       "  'kind': 0.047619047619047616,\n",
       "  'icy': 0.047619047619047616,\n",
       "  'cliff': 0.047619047619047616,\n",
       "  'unswept': 0.047619047619047616,\n",
       "  'landing': 0.047619047619047616,\n",
       "  'handrail': 0.047619047619047616,\n",
       "  'craters': 0.047619047619047616,\n",
       "  'world': 0.047619047619047616,\n",
       "  'cellar': 0.047619047619047616,\n",
       "  'mountain': 0.047619047619047616,\n",
       "  'ancient': 0.047619047619047616,\n",
       "  'new': 0.047619047619047616,\n",
       "  'papered': 0.047619047619047616,\n",
       "  'earth': 0.047619047619047616,\n",
       "  'cupboard': 0.047619047619047616},\n",
       " ('the', 'day'): {'the': 0.25, 'END': 0.25, 'began': 0.25, 'when': 0.25},\n",
       " ('day', 'the'): {'sun': 1.0},\n",
       " ('the', 'sun'): {'lets': 0.16666666666666666,\n",
       "  'END': 0.6666666666666666,\n",
       "  'in': 0.16666666666666666},\n",
       " ('lets', 'go'): {'END': 0.5, 'see': 0.5},\n",
       " ('sun', 'lets'): {'go': 1.0},\n",
       " ('ten', 'million'): {'silver': 1.0},\n",
       " ('million', 'silver'): {'lizards': 1.0},\n",
       " ('silver', 'lizards'): {'out': 1.0},\n",
       " ('lizards', 'out'): {'of': 1.0},\n",
       " ('of', 'snow'): {'END': 1.0},\n",
       " ('out', 'of'): {'snow': 0.05,\n",
       "  'beaten': 0.05,\n",
       "  'me': 0.05,\n",
       "  'ploughed': 0.05,\n",
       "  'the': 0.15,\n",
       "  'it': 0.2,\n",
       "  'bed': 0.05,\n",
       "  'gold': 0.05,\n",
       "  'idleness': 0.05,\n",
       "  'END': 0.05,\n",
       "  'you': 0.05,\n",
       "  'all': 0.05,\n",
       "  'forty': 0.05,\n",
       "  'life': 0.05,\n",
       "  'such': 0.05},\n",
       " ('as', 'often'): {'as': 1.0},\n",
       " ('often', 'as'): {'ive': 0.5, 'he': 0.5},\n",
       " ('as', 'ive'): {'seen': 1.0},\n",
       " ('ive', 'seen'): {'it': 1.0},\n",
       " ('seen', 'it'): {'done': 1.0},\n",
       " ('done', 'before'): {'END': 1.0},\n",
       " ('it', 'done'): {'before': 0.5, 'in': 0.5},\n",
       " ('i', 'cant'): {'pretend': 0.1111111111111111,\n",
       "  'decently': 0.1111111111111111,\n",
       "  'say': 0.1111111111111111,\n",
       "  'give': 0.1111111111111111,\n",
       "  'get': 0.1111111111111111,\n",
       "  'keep': 0.1111111111111111,\n",
       "  'talk': 0.1111111111111111,\n",
       "  'stay': 0.1111111111111111,\n",
       "  'explain': 0.1111111111111111},\n",
       " ('cant', 'pretend'): {'to': 1.0},\n",
       " ('pretend', 'to'): {'tell': 1.0},\n",
       " ('to', 'tell'): {'the': 0.6, 'them': 0.2, 'him': 0.2},\n",
       " ('tell', 'the'): {'way': 0.25, 'truth': 0.5, 'offers': 0.25},\n",
       " ('the', 'way'): {'its': 0.1111111111111111,\n",
       "  'he': 0.3333333333333333,\n",
       "  'home': 0.1111111111111111,\n",
       "  'a': 0.1111111111111111,\n",
       "  'you': 0.1111111111111111,\n",
       "  'to': 0.1111111111111111,\n",
       "  'hes': 0.1111111111111111},\n",
       " ('its', 'done'): {'END': 1.0},\n",
       " ('way', 'its'): {'done': 1.0},\n",
       " ('it', 'looks'): {'as': 0.5, 'that': 0.5},\n",
       " ('looks', 'as'): {'if': 1.0},\n",
       " ('as', 'if'): {'some': 0.1,\n",
       "  'for': 0.1,\n",
       "  'the': 0.1,\n",
       "  'id': 0.1,\n",
       "  'END': 0.2,\n",
       "  'it': 0.1,\n",
       "  'by': 0.1,\n",
       "  'and': 0.1,\n",
       "  'he': 0.1},\n",
       " ('if', 'some'): {'magic': 0.5, 'one': 0.5},\n",
       " ('some', 'magic'): {'of': 1.0},\n",
       " ('magic', 'of'): {'the': 1.0},\n",
       " ('lifted', 'the'): {'rug': 1.0},\n",
       " ('the', 'rug'): {'that': 1.0},\n",
       " ('rug', 'that'): {'bred': 1.0},\n",
       " ('that', 'bred'): {'them': 1.0},\n",
       " ('bred', 'them'): {'on': 1.0},\n",
       " ('them', 'on'): {'the': 1.0},\n",
       " ('the', 'floor'): {'END': 0.6, 'myself': 0.2, 'and': 0.2},\n",
       " ('and', 'the'): {'light': 0.08333333333333333,\n",
       "  'sun': 0.08333333333333333,\n",
       "  'temptation': 0.08333333333333333,\n",
       "  'birds': 0.08333333333333333,\n",
       "  'fur': 0.08333333333333333,\n",
       "  'north': 0.08333333333333333,\n",
       "  'clothes': 0.08333333333333333,\n",
       "  'jug': 0.08333333333333333,\n",
       "  'bandmusic': 0.08333333333333333,\n",
       "  'smell': 0.08333333333333333,\n",
       "  'hens': 0.08333333333333333,\n",
       "  'cock': 0.08333333333333333},\n",
       " ('the', 'light'): {'breaking': 0.2, 'from': 0.2, 'END': 0.4, 'and': 0.2},\n",
       " ('light', 'breaking'): {'on': 1.0},\n",
       " ('breaking', 'on'): {'them': 1.0},\n",
       " ('on', 'them'): {'made': 0.5, 'END': 0.5},\n",
       " ('them', 'made'): {'them': 1.0},\n",
       " ('them', 'run'): {'END': 1.0},\n",
       " ('made', 'them'): {'run': 1.0},\n",
       " ('i', 'though'): {'to': 1.0},\n",
       " ('though', 'to'): {'stop': 1.0},\n",
       " ('stop', 'the'): {'wet': 1.0},\n",
       " ('wet', 'stampede'): {'END': 1.0},\n",
       " ('the', 'wet'): {'stampede': 0.5, 'feathers': 0.5},\n",
       " ('and', 'caught'): {'one': 1.0},\n",
       " ('caught', 'one'): {'silver': 1.0},\n",
       " ('one', 'silver'): {'lizard': 1.0},\n",
       " ('silver', 'lizard'): {'by': 1.0},\n",
       " ('lizard', 'by'): {'the': 1.0},\n",
       " ('the', 'tail'): {'END': 0.5, 'of': 0.5},\n",
       " ('and', 'put'): {'my': 0.5, 'a': 0.5},\n",
       " ('put', 'my'): {'foot': 1.0},\n",
       " ('my', 'foot'): {'on': 1.0},\n",
       " ('foot', 'on'): {'one': 1.0},\n",
       " ('on', 'one'): {'without': 1.0},\n",
       " ('without', 'avail'): {'END': 1.0},\n",
       " ('one', 'without'): {'avail': 1.0},\n",
       " ('and', 'threw'): {'myself': 1.0},\n",
       " ('threw', 'myself'): {'wetelbowed': 1.0},\n",
       " ('myself', 'wetelbowed'): {'and': 1.0},\n",
       " ('and', 'wetkneed'): {'END': 1.0},\n",
       " ('wetelbowed', 'and'): {'wetkneed': 1.0},\n",
       " ('in', 'front'): {'of': 1.0},\n",
       " ('front', 'of'): {'twenty': 0.3333333333333333,\n",
       "  'one': 0.3333333333333333,\n",
       "  'every': 0.3333333333333333},\n",
       " ('of', 'twenty'): {'others': 0.5, 'then': 0.5},\n",
       " ('twenty', 'others'): {'wriggling': 1.0},\n",
       " ('wriggling', 'speed'): {'END': 1.0},\n",
       " ('others', 'wriggling'): {'speed': 1.0},\n",
       " ('the', 'confusion'): {'of': 1.0},\n",
       " ('confusion', 'of'): {'them': 1.0},\n",
       " ('of', 'them'): {'all': 0.125,\n",
       "  'END': 0.25,\n",
       "  'you': 0.125,\n",
       "  'to': 0.125,\n",
       "  'put': 0.125,\n",
       "  'for': 0.125,\n",
       "  'are': 0.125},\n",
       " ('all', 'aglitter'): {'END': 1.0},\n",
       " ('them', 'all'): {'aglitter': 1.0},\n",
       " ('and', 'birds'): {'that': 1.0},\n",
       " ('birds', 'that'): {'joined': 1.0},\n",
       " ('that', 'joined'): {'in': 1.0},\n",
       " ('joined', 'in'): {'the': 1.0},\n",
       " ('excited', 'fun'): {'END': 1.0},\n",
       " ('the', 'excited'): {'fun': 1.0},\n",
       " ('by', 'doubling'): {'and': 1.0},\n",
       " ('doubling', 'and'): {'redoubling': 1.0},\n",
       " ('and', 'redoubling'): {'song': 1.0},\n",
       " ('redoubling', 'song'): {'and': 1.0},\n",
       " ('and', 'twitter'): {'END': 1.0},\n",
       " ('song', 'and'): {'twitter': 1.0},\n",
       " ('have', 'no'): {'doubt': 1.0},\n",
       " ('no', 'doubt'): {'id': 0.5, 'its': 0.5},\n",
       " ('doubt', 'id'): {'end': 1.0},\n",
       " ('id', 'end'): {'by': 1.0},\n",
       " ('end', 'by'): {'holding': 1.0},\n",
       " ('holding', 'none'): {'END': 1.0},\n",
       " ('by', 'holding'): {'none': 1.0},\n",
       " ('it', 'takes'): {'the': 0.5, 'all': 0.5},\n",
       " ('takes', 'the'): {'moon': 0.5, 'money': 0.5},\n",
       " ('the', 'moon'): {'for': 0.3333333333333333,\n",
       "  'a': 0.3333333333333333,\n",
       "  'was': 0.3333333333333333},\n",
       " ('moon', 'for'): {'this': 1.0},\n",
       " ('for', 'this'): {'the': 0.3333333333333333,\n",
       "  'walk': 0.3333333333333333,\n",
       "  'cock': 0.3333333333333333},\n",
       " ('this', 'the'): {'suns': 0.5, 'road': 0.5},\n",
       " ('the', 'suns'): {'a': 1.0},\n",
       " ('a', 'wizard'): {'END': 1.0},\n",
       " ('suns', 'a'): {'wizard': 1.0},\n",
       " ('by', 'all'): {'i': 1.0},\n",
       " ('all', 'i'): {'tell': 1.0},\n",
       " ('i', 'tell'): {'but': 0.3333333333333333, 'them': 0.6666666666666666},\n",
       " ('tell', 'but'): {'sos': 1.0},\n",
       " ('but', 'sos'): {'the': 1.0},\n",
       " ('sos', 'the'): {'moon': 0.5, 'chin': 0.5},\n",
       " ('a', 'witch'): {'END': 0.4, 'id': 0.2, 'or': 0.2, 'who': 0.2},\n",
       " ('moon', 'a'): {'witch': 1.0},\n",
       " ('the', 'high'): {'west': 1.0},\n",
       " ('high', 'west'): {'she': 1.0},\n",
       " ('west', 'she'): {'makes': 1.0},\n",
       " ('she', 'makes'): {'a': 1.0},\n",
       " ('makes', 'a'): {'gentle': 0.5, 'night': 0.5},\n",
       " ('gentle', 'cast'): {'END': 1.0},\n",
       " ('a', 'gentle'): {'cast': 0.5, 'lot': 0.5},\n",
       " ('and', 'suddenly'): {'without': 1.0},\n",
       " ('suddenly', 'without'): {'a': 1.0},\n",
       " ('a', 'jerk'): {'or': 1.0},\n",
       " ('or', 'twitch'): {'END': 1.0},\n",
       " ('jerk', 'or'): {'twitch': 1.0},\n",
       " ('she', 'has'): {'her': 1.0},\n",
       " ('has', 'her'): {'speel': 1.0},\n",
       " ('her', 'speel'): {'on': 1.0},\n",
       " ('speel', 'on'): {'every': 1.0},\n",
       " ('on', 'every'): {'single': 1.0},\n",
       " ('single', 'lizard'): {'END': 1.0},\n",
       " ('every', 'single'): {'lizard': 1.0},\n",
       " ('i', 'fancied'): {'when': 1.0},\n",
       " ('fancied', 'when'): {'i': 1.0},\n",
       " ('i', 'looked'): {'at': 1.0},\n",
       " ('looked', 'at'): {'six': 0.5, 'nine': 0.5},\n",
       " ('six', 'oclock'): {'END': 1.0},\n",
       " ('at', 'six'): {'oclock': 1.0},\n",
       " ('the', 'swarm'): {'still': 0.3333333333333333,\n",
       "  'was': 0.3333333333333333,\n",
       "  'END': 0.3333333333333333},\n",
       " ('swarm', 'still'): {'ran': 1.0},\n",
       " ('still', 'ran'): {'and': 1.0},\n",
       " ('ran', 'and'): {'scuttled': 0.5, 'shouted': 0.5},\n",
       " ('and', 'scuttled'): {'just': 1.0},\n",
       " ('scuttled', 'just'): {'as': 1.0},\n",
       " ('as', 'fast'): {'END': 1.0},\n",
       " ('moon', 'was'): {'waiting': 1.0},\n",
       " ('was', 'waiting'): {'for': 1.0},\n",
       " ('waiting', 'for'): {'her': 0.5, 'things': 0.5},\n",
       " ('for', 'her'): {'chill': 0.3333333333333333,\n",
       "  'all': 0.3333333333333333,\n",
       "  'mother': 0.3333333333333333},\n",
       " ('chill', 'effect'): {'END': 1.0},\n",
       " ('her', 'chill'): {'effect': 1.0},\n",
       " ('at', 'nine'): {'the': 1.0},\n",
       " ('nine', 'the'): {'swarm': 1.0},\n",
       " ('swarm', 'was'): {'turned': 1.0},\n",
       " ('was', 'turned'): {'to': 1.0},\n",
       " ('to', 'rock'): {'END': 1.0},\n",
       " ('turned', 'to'): {'rock': 1.0},\n",
       " ('in', 'every'): {'lifelike': 0.3333333333333333,\n",
       "  'open': 0.3333333333333333,\n",
       "  'way': 0.3333333333333333},\n",
       " ('every', 'lifelike'): {'posture': 1.0},\n",
       " ('lifelike', 'posture'): {'of': 1.0},\n",
       " ('posture', 'of'): {'the': 1.0},\n",
       " ('transfixed', 'on'): {'mountain': 1.0},\n",
       " ('on', 'mountain'): {'slopes': 1.0},\n",
       " ('mountain', 'slopes'): {'almost': 1.0},\n",
       " ('almost', 'erect'): {'END': 1.0},\n",
       " ('slopes', 'almost'): {'erect': 1.0},\n",
       " ('across', 'each'): {'other': 1.0},\n",
       " ('each', 'other'): {'and': 0.2, 'END': 0.4, 'both': 0.2, 'i': 0.2},\n",
       " ('other', 'and'): {'side': 1.0},\n",
       " ('and', 'side'): {'by': 1.0},\n",
       " ('side', 'by'): {'side': 1.0},\n",
       " ('by', 'side'): {'they': 1.0},\n",
       " ('they', 'lay'): {'END': 1.0},\n",
       " ('side', 'they'): {'lay': 1.0},\n",
       " ('the', 'spell'): {'that': 1.0},\n",
       " ('spell', 'that'): {'so': 1.0},\n",
       " ('that', 'so'): {'could': 1.0},\n",
       " ('so', 'could'): {'hold': 1.0},\n",
       " ('could', 'hold'): {'them': 1.0},\n",
       " ('hold', 'them'): {'as': 1.0},\n",
       " ('them', 'as'): {'they': 1.0},\n",
       " ('they', 'were'): {'END': 0.2,\n",
       "  'robinsons': 0.1,\n",
       "  'mounted': 0.1,\n",
       "  'a': 0.1,\n",
       "  'sprung': 0.1,\n",
       "  'at': 0.1,\n",
       "  'was': 0.1,\n",
       "  'beside': 0.1,\n",
       "  'crooking': 0.1},\n",
       " ('as', 'they'): {'were': 1.0},\n",
       " ('was', 'wrought'): {'through': 1.0},\n",
       " ('wrought', 'through'): {'trees': 1.0},\n",
       " ('through', 'trees'): {'without': 1.0},\n",
       " ('trees', 'without'): {'a': 1.0},\n",
       " ('a', 'breath'): {'of': 1.0},\n",
       " ('of', 'storm'): {'END': 1.0},\n",
       " ('breath', 'of'): {'storm': 0.5, 'air': 0.5},\n",
       " ('to', 'make'): {'a': 0.3333333333333333,\n",
       "  'it': 0.3333333333333333,\n",
       "  'so': 0.16666666666666666,\n",
       "  'them': 0.16666666666666666},\n",
       " ('make', 'a'): {'leaf': 0.3333333333333333,\n",
       "  'present': 0.3333333333333333,\n",
       "  'common': 0.3333333333333333},\n",
       " ('leaf', 'if'): {'there': 1.0},\n",
       " ('there', 'had'): {'been': 1.0},\n",
       " ('had', 'been'): {'one': 0.16666666666666666,\n",
       "  'down': 0.16666666666666666,\n",
       "  'too': 0.16666666666666666,\n",
       "  'dark': 0.16666666666666666,\n",
       "  'for': 0.16666666666666666,\n",
       "  'to': 0.16666666666666666},\n",
       " ('one', 'stir'): {'END': 1.0},\n",
       " ('one', 'lizard'): {'at': 1.0},\n",
       " ('lizard', 'at'): {'the': 1.0},\n",
       " ('at', 'the'): {'end': 0.14285714285714285,\n",
       "  'time': 0.14285714285714285,\n",
       "  'door': 0.14285714285714285,\n",
       "  'stake': 0.14285714285714285,\n",
       "  'level': 0.14285714285714285,\n",
       "  'waterside': 0.14285714285714285,\n",
       "  'kitchen': 0.14285714285714285},\n",
       " ('the', 'end'): {'of': 0.5, 'END': 0.5},\n",
       " ('end', 'of'): {'every': 1.0},\n",
       " ('every', 'ray'): {'END': 1.0},\n",
       " ('of', 'every'): {'ray': 0.5, 'one': 0.5},\n",
       " ('the', 'thought'): {'of': 1.0},\n",
       " ('thought', 'of'): {'my': 0.5, 'standing': 0.5},\n",
       " ('of', 'my'): {'attempting': 1.0},\n",
       " ('my', 'attempting'): {'such': 1.0},\n",
       " ('attempting', 'such'): {'a': 1.0},\n",
       " ('a', 'stray'): {'END': 1.0},\n",
       " ('such', 'a'): {'stray': 0.1111111111111111,\n",
       "  'lofty': 0.1111111111111111,\n",
       "  'ghost': 0.1111111111111111,\n",
       "  'crystal': 0.1111111111111111,\n",
       "  'hole': 0.1111111111111111,\n",
       "  'wild': 0.1111111111111111,\n",
       "  'time': 0.1111111111111111,\n",
       "  'case': 0.1111111111111111,\n",
       "  'mess': 0.1111111111111111},\n",
       " ('once', 'on'): {'the': 0.5, 'kinsman': 0.5},\n",
       " ('the', 'kind'): {'of': 0.5, 'END': 0.5},\n",
       " ('kind', 'of'): {'day': 1.0},\n",
       " ('of', 'day'): {'called': 1.0},\n",
       " ('day', 'called'): {'weather': 1.0},\n",
       " ('weather', 'breeder'): {'END': 1.0},\n",
       " ('called', 'weather'): {'breeder': 1.0},\n",
       " ('when', 'the'): {'heat': 0.2,\n",
       "  'wind': 0.2,\n",
       "  'bed': 0.2,\n",
       "  'storm': 0.2,\n",
       "  'chimneys': 0.2},\n",
       " ('the', 'heat'): {'slowly': 0.5, 'END': 0.5},\n",
       " ('heat', 'slowly'): {'hazes': 1.0},\n",
       " ('slowly', 'hazes'): {'and': 1.0},\n",
       " ('hazes', 'and'): {'the': 1.0},\n",
       " ('by', 'its'): {'own': 1.0},\n",
       " ('its', 'own'): {'power': 1.0},\n",
       " ('own', 'power'): {'seems': 1.0},\n",
       " ('power', 'seems'): {'to': 1.0},\n",
       " ('seems', 'to'): {'be': 0.5, 'have': 0.5},\n",
       " ('be', 'undone'): {'END': 1.0},\n",
       " ('to', 'be'): {'undone': 0.07142857142857142,\n",
       "  'broken': 0.07142857142857142,\n",
       "  'cruel': 0.07142857142857142,\n",
       "  'thrown': 0.07142857142857142,\n",
       "  'enough': 0.07142857142857142,\n",
       "  'mad': 0.07142857142857142,\n",
       "  'heard': 0.07142857142857142,\n",
       "  'salted': 0.07142857142857142,\n",
       "  'good': 0.07142857142857142,\n",
       "  'you': 0.07142857142857142,\n",
       "  'in': 0.07142857142857142,\n",
       "  'a': 0.07142857142857142,\n",
       "  'as': 0.07142857142857142,\n",
       "  'the': 0.07142857142857142},\n",
       " ('i', 'was'): {'half': 0.07142857142857142,\n",
       "  'married': 0.14285714285714285,\n",
       "  'to': 0.07142857142857142,\n",
       "  'a': 0.21428571428571427,\n",
       "  'young': 0.14285714285714285,\n",
       "  'soon': 0.07142857142857142,\n",
       "  'going': 0.07142857142857142,\n",
       "  'END': 0.07142857142857142,\n",
       "  'just': 0.07142857142857142,\n",
       "  'too': 0.07142857142857142},\n",
       " ('was', 'half'): {'boring': 1.0},\n",
       " ('half', 'boring'): {'through': 1.0},\n",
       " ('boring', 'through'): {'half': 1.0},\n",
       " ('through', 'half'): {'climbing': 1.0},\n",
       " ('climbing', 'through'): {'END': 1.0},\n",
       " ('half', 'climbing'): {'through': 1.0},\n",
       " ('a', 'swamp'): {'of': 1.0},\n",
       " ('swamp', 'of'): {'cedar': 1.0},\n",
       " ('of', 'cedar'): {'choked': 0.5, 'END': 0.5},\n",
       " ('cedar', 'choked'): {'with': 1.0},\n",
       " ('choked', 'with'): {'oil': 1.0},\n",
       " ('with', 'oil'): {'of': 1.0},\n",
       " ('oil', 'of'): {'cedar': 1.0},\n",
       " ('and', 'scurf'): {'of': 1.0},\n",
       " ('scurf', 'of'): {'plants': 1.0},\n",
       " ('of', 'plants'): {'and': 1.0},\n",
       " ('plants', 'and'): {'weary': 1.0},\n",
       " ('and', 'weary'): {'and': 1.0},\n",
       " ('and', 'overheated'): {'END': 1.0},\n",
       " ('weary', 'and'): {'overheated': 1.0},\n",
       " ('i', 'ever'): {'left': 0.5, 'cared': 0.5},\n",
       " ('ever', 'left'): {'the': 1.0},\n",
       " ('left', 'the'): {'road': 0.25, 'cellar': 0.25, 'storm': 0.25, 'named': 0.25},\n",
       " ('the', 'road'): {'i': 0.3333333333333333,\n",
       "  'END': 0.3333333333333333,\n",
       "  'there': 0.3333333333333333},\n",
       " ('i', 'knew'): {'END': 0.25, 'in': 0.25, 'them': 0.25, 'there': 0.25},\n",
       " ('road', 'i'): {'knew': 0.5, 'didnt': 0.5},\n",
       " ('i', 'paused'): {'and': 1.0},\n",
       " ('paused', 'and'): {'rested': 1.0},\n",
       " ('and', 'rested'): {'on': 1.0},\n",
       " ('rested', 'on'): {'a': 1.0},\n",
       " ('on', 'a'): {'sort': 0.25,\n",
       "  'lookoff': 0.125,\n",
       "  'bough': 0.125,\n",
       "  'hill': 0.125,\n",
       "  'lake': 0.125,\n",
       "  'screen': 0.125,\n",
       "  'plane': 0.125},\n",
       " ('a', 'sort'): {'of': 1.0},\n",
       " ('of', 'hook'): {'END': 1.0},\n",
       " ('sort', 'of'): {'hook': 0.2,\n",
       "  'turn': 0.2,\n",
       "  'passport': 0.2,\n",
       "  'bakeshop': 0.2,\n",
       "  'swear': 0.2},\n",
       " ('that', 'had'): {'me': 0.3333333333333333,\n",
       "  'been': 0.3333333333333333,\n",
       "  'budded': 0.3333333333333333},\n",
       " ('had', 'me'): {'by': 1.0},\n",
       " ('me', 'by'): {'the': 1.0},\n",
       " ('the', 'coat'): {'as': 1.0},\n",
       " ('coat', 'as'): {'good': 1.0},\n",
       " ('as', 'good'): {'as': 0.5, 'END': 0.25, 'they': 0.25},\n",
       " ('as', 'seated'): {'END': 1.0},\n",
       " ('good', 'as'): {'seated': 0.5, 'own': 0.5},\n",
       " ('and', 'since'): {'there': 0.5, 'it': 0.5},\n",
       " ('since', 'there'): {'was': 1.0},\n",
       " ('there', 'was'): {'no': 0.5,\n",
       "  'water': 0.16666666666666666,\n",
       "  'to': 0.16666666666666666,\n",
       "  'an': 0.16666666666666666},\n",
       " ('was', 'no'): {'other': 0.25,\n",
       "  'playhouse': 0.25,\n",
       "  'quarrel': 0.25,\n",
       "  'property': 0.25},\n",
       " ('no', 'other'): {'way': 1.0},\n",
       " ('other', 'way'): {'to': 0.5, 'END': 0.5},\n",
       " ('to', 'look'): {'END': 0.6666666666666666, 'too': 0.3333333333333333},\n",
       " ('way', 'to'): {'look': 0.3333333333333333,\n",
       "  'me': 0.3333333333333333,\n",
       "  'END': 0.3333333333333333},\n",
       " ('looked', 'up'): {'toward': 1.0},\n",
       " ('up', 'toward'): {'heaven': 1.0},\n",
       " ('toward', 'heaven'): {'and': 1.0},\n",
       " ('heaven', 'and'): {'there': 1.0},\n",
       " ('and', 'there'): {'against': 0.5, 'a': 0.5},\n",
       " ('there', 'against'): {'the': 1.0},\n",
       " ('the', 'blue'): {'END': 1.0},\n",
       " ('stood', 'over'): {'me': 1.0},\n",
       " ('over', 'me'): {'a': 1.0},\n",
       " ('me', 'a'): {'resurrected': 0.3333333333333333,\n",
       "  'witch': 0.3333333333333333,\n",
       "  'chimney': 0.3333333333333333},\n",
       " ('resurrected', 'tree'): {'END': 1.0},\n",
       " ('a', 'resurrected'): {'tree': 1.0},\n",
       " ('tree', 'that'): {'had': 1.0},\n",
       " ('been', 'down'): {'and': 1.0},\n",
       " ('down', 'and'): {'raised': 1.0},\n",
       " ('raised', 'again'): {'END': 1.0},\n",
       " ('and', 'raised'): {'again': 1.0},\n",
       " ('a', 'barkless'): {'spectre': 1.0},\n",
       " ('barkless', 'spectre'): {'he': 1.0},\n",
       " ('spectre', 'he'): {'had': 1.0},\n",
       " ('he', 'had'): {'halted': 0.2,\n",
       "  'on': 0.2,\n",
       "  'besides': 0.2,\n",
       "  'in': 0.2,\n",
       "  'to': 0.2},\n",
       " ('halted', 'too'): {'END': 1.0},\n",
       " ('had', 'halted'): {'too': 1.0},\n",
       " ('if', 'for'): {'fear': 1.0},\n",
       " ('for', 'fear'): {'of': 1.0},\n",
       " ('fear', 'of'): {'treading': 1.0},\n",
       " ('of', 'treading'): {'upon': 1.0},\n",
       " ('upon', 'me'): {'END': 1.0},\n",
       " ('treading', 'upon'): {'me': 1.0},\n",
       " ('i', 'saw'): {'the': 0.2, 'it': 0.2, 'a': 0.2, 'no': 0.2, 'him': 0.2},\n",
       " ('saw', 'the'): {'strange': 1.0},\n",
       " ('the', 'strange'): {'position': 1.0},\n",
       " ('strange', 'position'): {'of': 1.0},\n",
       " ('position', 'of'): {'his': 1.0},\n",
       " ('his', 'hands'): {'END': 1.0},\n",
       " ('of', 'his'): {'hands': 0.2,\n",
       "  'own': 0.2,\n",
       "  'bed': 0.2,\n",
       "  'eyes': 0.2,\n",
       "  'old': 0.2},\n",
       " ('up', 'at'): {'his': 1.0},\n",
       " ('at', 'his'): {'shoulders': 0.3333333333333333,\n",
       "  'feet': 0.3333333333333333,\n",
       "  'age': 0.3333333333333333},\n",
       " ('his', 'shoulders'): {'dragging': 1.0},\n",
       " ('shoulders', 'dragging'): {'yellow': 1.0},\n",
       " ('yellow', 'strands'): {'END': 1.0},\n",
       " ('dragging', 'yellow'): {'strands': 1.0},\n",
       " ('of', 'wire'): {'with': 1.0},\n",
       " ('wire', 'with'): {'something': 1.0},\n",
       " ('with', 'something'): {'in': 1.0},\n",
       " ('something', 'in'): {'it': 1.0},\n",
       " ('in', 'it'): {'from': 0.16666666666666666,\n",
       "  'END': 0.3333333333333333,\n",
       "  'sweet': 0.16666666666666666,\n",
       "  'now': 0.16666666666666666,\n",
       "  'a': 0.16666666666666666},\n",
       " ('it', 'from'): {'men': 1.0},\n",
       " ('from', 'men'): {'to': 1.0},\n",
       " ('to', 'men'): {'END': 1.0},\n",
       " ('men', 'to'): {'men': 1.0},\n",
       " ('you', 'here'): {'i': 0.5, 'you': 0.5},\n",
       " ('here', 'i'): {'said': 0.5, 'dont': 0.5},\n",
       " ('i', 'said'): {'where': 1.0},\n",
       " ('said', 'where'): {'arent': 1.0},\n",
       " ('where', 'arent'): {'you': 1.0},\n",
       " ('you', 'nowadays'): {'END': 1.0},\n",
       " ('arent', 'you'): {'nowadays': 0.3333333333333333,\n",
       "  'fond': 0.3333333333333333,\n",
       "  'afraid': 0.3333333333333333},\n",
       " ('and', 'whats'): {'the': 1.0},\n",
       " ('whats', 'the'): {'news': 0.25, 'real': 0.25, 'use': 0.25, 'hurry': 0.25},\n",
       " ('the', 'news'): {'you': 1.0},\n",
       " ('news', 'you'): {'carryif': 0.5, 'dreadful': 0.5},\n",
       " ('you', 'carryif'): {'you': 1.0},\n",
       " ('you', 'know'): {'END': 0.42857142857142855,\n",
       "  'who': 0.14285714285714285,\n",
       "  'we': 0.14285714285714285,\n",
       "  'if': 0.14285714285714285,\n",
       "  'how': 0.14285714285714285},\n",
       " ('carryif', 'you'): {'know': 1.0},\n",
       " ('me', 'where'): {'youre': 0.5, 'i': 0.5},\n",
       " ('where', 'youre'): {'off': 1.0},\n",
       " ('off', 'formontreal'): {'END': 1.0},\n",
       " ('youre', 'off'): {'formontreal': 1.0},\n",
       " ('me', 'im'): {'not': 1.0},\n",
       " ('im', 'not'): {'off': 0.5, 'blaming': 0.5},\n",
       " ('not', 'off'): {'for': 1.0},\n",
       " ('off', 'for'): {'anywhere': 1.0},\n",
       " ('for', 'anywhere'): {'at': 1.0},\n",
       " ('at', 'all'): {'END': 0.5, 'with': 0.5},\n",
       " ('anywhere', 'at'): {'all': 1.0},\n",
       " ('sometimes', 'i'): {'wander': 1.0},\n",
       " ('i', 'wander'): {'out': 1.0},\n",
       " ('wander', 'out'): {'of': 1.0},\n",
       " ('beaten', 'ways'): {'END': 1.0},\n",
       " ('of', 'beaten'): {'ways': 1.0},\n",
       " ('half', 'looking'): {'for': 1.0},\n",
       " ('looking', 'for'): {'the': 0.3333333333333333,\n",
       "  'or': 0.3333333333333333,\n",
       "  'another': 0.3333333333333333},\n",
       " ('for', 'the'): {'orchid': 0.07692307692307693,\n",
       "  'reason': 0.07692307692307693,\n",
       "  'chance': 0.07692307692307693,\n",
       "  'time': 0.07692307692307693,\n",
       "  'novelty': 0.07692307692307693,\n",
       "  'proof': 0.07692307692307693,\n",
       "  'place': 0.07692307692307693,\n",
       "  'woods': 0.07692307692307693,\n",
       "  'house': 0.07692307692307693,\n",
       "  'first': 0.07692307692307693,\n",
       "  'clock': 0.07692307692307693,\n",
       "  'wonder': 0.07692307692307693,\n",
       "  'board': 0.07692307692307693},\n",
       " ('orchid', 'calypso'): {'END': 1.0},\n",
       " ('the', 'orchid'): {'calypso': 1.0},\n",
       " ('brown', 'lived'): {'at': 1.0},\n",
       " ('lived', 'at'): {'such': 1.0},\n",
       " ('at', 'such'): {'a': 0.5, 'an': 0.25, 'things': 0.25},\n",
       " ('lofty', 'farm'): {'END': 1.0},\n",
       " ('a', 'lofty'): {'farm': 1.0},\n",
       " ('that', 'everyone'): {'for': 1.0},\n",
       " ('everyone', 'for'): {'miles': 1.0},\n",
       " ('for', 'miles'): {'could': 1.0},\n",
       " ('could', 'see'): {'END': 0.5, 'nothing': 0.25, 'it': 0.25},\n",
       " ('miles', 'could'): {'see': 1.0},\n",
       " ('his', 'lantern'): {'when': 0.5, 'saying': 0.5},\n",
       " ('lantern', 'when'): {'he': 1.0},\n",
       " ('when', 'he'): {'did': 1.0},\n",
       " ('he', 'did'): {'his': 0.5, 'in': 0.5},\n",
       " ('his', 'chores'): {'END': 1.0},\n",
       " ('did', 'his'): {'chores': 1.0},\n",
       " ('in', 'winter'): {'after': 0.5, 'when': 0.5},\n",
       " ('winter', 'after'): {'halfpast': 1.0},\n",
       " ('halfpast', 'three'): {'END': 1.0},\n",
       " ('after', 'halfpast'): {'three': 1.0},\n",
       " ('and', 'many'): {'must': 1.0},\n",
       " ('many', 'must'): {'have': 1.0},\n",
       " ('must', 'have'): {'seen': 0.16666666666666666,\n",
       "  'looked': 0.16666666666666666,\n",
       "  'heard': 0.3333333333333333,\n",
       "  'learned': 0.16666666666666666,\n",
       "  'changed': 0.16666666666666666},\n",
       " ('have', 'seen'): {'him': 0.5, 'visions': 0.5},\n",
       " ('him', 'make'): {'END': 1.0},\n",
       " ('seen', 'him'): {'make': 0.5, 'strange': 0.5},\n",
       " ('his', 'wild'): {'descent': 1.0},\n",
       " ('wild', 'descent'): {'from': 0.5, 'END': 0.5},\n",
       " ('descent', 'from'): {'there': 1.0},\n",
       " ('from', 'there'): {'one': 1.0},\n",
       " ('one', 'night'): {'END': 0.5, 'in': 0.5},\n",
       " ('there', 'one'): {'night': 1.0},\n",
       " ('cross', 'lots'): {'cross': 1.0},\n",
       " ('lots', 'cross'): {'walls': 1.0},\n",
       " ('cross', 'walls'): {'cross': 1.0},\n",
       " ('cross', 'everything'): {'END': 1.0},\n",
       " ('walls', 'cross'): {'everything': 1.0},\n",
       " ('describing', 'rings'): {'of': 1.0},\n",
       " ('rings', 'of'): {'lantern': 1.0},\n",
       " ('lantern', 'light'): {'END': 1.0},\n",
       " ('of', 'lantern'): {'light': 1.0},\n",
       " ('the', 'house'): {'and': 0.25, 'as': 0.25, 'that': 0.25, 'END': 0.25},\n",
       " ('house', 'and'): {'barn': 1.0},\n",
       " ('and', 'barn'): {'the': 1.0},\n",
       " ('the', 'gale'): {'END': 1.0},\n",
       " ('barn', 'the'): {'gale': 1.0},\n",
       " ('got', 'him'): {'by': 1.0},\n",
       " ('him', 'by'): {'something': 1.0},\n",
       " ('by', 'something'): {'he': 1.0},\n",
       " ('something', 'he'): {'had': 1.0},\n",
       " ('had', 'on'): {'END': 1.0},\n",
       " ('and', 'blew'): {'him': 1.0},\n",
       " ('blew', 'him'): {'out': 1.0},\n",
       " ('him', 'out'): {'on': 0.5, 'in': 0.5},\n",
       " ('out', 'on'): {'the': 0.5, 'a': 0.5},\n",
       " ('icy', 'crust'): {'END': 1.0},\n",
       " ('the', 'icy'): {'crust': 1.0},\n",
       " ('that', 'cased'): {'the': 1.0},\n",
       " ('cased', 'the'): {'world': 1.0},\n",
       " ('world', 'and'): {'he': 0.5, 'try': 0.5},\n",
       " ('and', 'he'): {'was': 0.5, 'liked': 0.5},\n",
       " ('was', 'gone'): {'END': 1.0},\n",
       " ('he', 'was'): {'gone': 0.14285714285714285,\n",
       "  'headed': 0.14285714285714285,\n",
       "  'END': 0.2857142857142857,\n",
       "  'none': 0.14285714285714285,\n",
       "  'plagued': 0.14285714285714285,\n",
       "  'given': 0.14285714285714285},\n",
       " ('walls', 'were'): {'all': 1.0},\n",
       " ('were', 'all'): {'buried': 0.3333333333333333,\n",
       "  'those': 0.3333333333333333,\n",
       "  'mad': 0.3333333333333333},\n",
       " ('all', 'buried'): {'trees': 1.0},\n",
       " ('buried', 'trees'): {'were': 1.0},\n",
       " ('were', 'few'): {'END': 1.0},\n",
       " ('trees', 'were'): {'few': 1.0},\n",
       " ('he', 'saw'): {'no': 1.0},\n",
       " ('saw', 'no'): {'stay': 0.5, 'window': 0.5},\n",
       " ('no', 'stay'): {'unless': 1.0},\n",
       " ('stay', 'unless'): {'he': 1.0},\n",
       " ('he', 'stove'): {'END': 1.0},\n",
       " ('unless', 'he'): {'stove': 1.0},\n",
       " ('a', 'hole'): {'in': 0.5, 'i': 0.5},\n",
       " ('hole', 'in'): {'somewhere': 0.5, 'a': 0.5},\n",
       " ('in', 'somewhere'): {'with': 1.0},\n",
       " ('somewhere', 'with'): {'his': 1.0},\n",
       " ('his', 'heel'): {'END': 1.0},\n",
       " ('with', 'his'): {'heel': 0.5, 'pipe': 0.5},\n",
       " ('but', 'though'): {'repeatedly': 0.5, 'it': 0.5},\n",
       " ('though', 'repeatedly'): {'he': 1.0},\n",
       " ('he', 'strove'): {'END': 1.0},\n",
       " ('repeatedly', 'he'): {'strove': 1.0},\n",
       " ('and', 'stamped'): {'and': 1.0},\n",
       " ('stamped', 'and'): {'said': 1.0},\n",
       " ('and', 'said'): {'things': 1.0},\n",
       " ('said', 'things'): {'to': 1.0},\n",
       " ('to', 'himself'): {'END': 1.0},\n",
       " ('things', 'to'): {'himself': 0.5, 'happen': 0.5},\n",
       " ('and', 'sometimes'): {'something': 1.0},\n",
       " ('sometimes', 'something'): {'seemed': 1.0},\n",
       " ('something', 'seemed'): {'to': 1.0},\n",
       " ('to', 'yield'): {'END': 1.0},\n",
       " ('seemed', 'to'): {'yield': 1.0},\n",
       " ('he', 'gained'): {'no': 1.0},\n",
       " ('gained', 'no'): {'foothold': 1.0},\n",
       " ('no', 'foothold'): {'but': 1.0},\n",
       " ('but', 'pursued'): {'END': 1.0},\n",
       " ('foothold', 'but'): {'pursued': 1.0},\n",
       " ('his', 'journey'): {'down': 1.0},\n",
       " ('journey', 'down'): {'from': 1.0},\n",
       " ('down', 'from'): {'field': 0.5, 'everything': 0.5},\n",
       " ('from', 'field'): {'to': 1.0},\n",
       " ('to', 'field'): {'END': 1.0},\n",
       " ('field', 'to'): {'field': 1.0},\n",
       " ('sometimes', 'he'): {'came': 0.5, 'gets': 0.5},\n",
       " ('he', 'came'): {'with': 0.5, 'at': 0.5},\n",
       " ('came', 'with'): {'arms': 0.5, 'cart': 0.5},\n",
       " ('arms', 'outspread'): {'END': 1.0},\n",
       " ('with', 'arms'): {'outspread': 1.0},\n",
       " ('like', 'wings'): {'revolving': 1.0},\n",
       " ('wings', 'revolving'): {'in': 1.0},\n",
       " ('revolving', 'in'): {'the': 1.0},\n",
       " ('the', 'scene'): {'END': 1.0},\n",
       " ('upon', 'his'): {'longer': 1.0},\n",
       " ('his', 'longer'): {'axis': 1.0},\n",
       " ('axis', 'and'): {'END': 1.0},\n",
       " ('longer', 'axis'): {'and': 1.0},\n",
       " ('with', 'no'): {'small': 1.0},\n",
       " ('no', 'small'): {'dignity': 1.0},\n",
       " ('small', 'dignity'): {'of': 1.0},\n",
       " ('of', 'mien'): {'END': 1.0},\n",
       " ('dignity', 'of'): {'mien': 1.0},\n",
       " ('faster', 'or'): {'slower': 1.0},\n",
       " ('or', 'slower'): {'as': 1.0},\n",
       " ('slower', 'as'): {'he': 1.0},\n",
       " ('he', 'chanced'): {'END': 1.0},\n",
       " ('as', 'he'): {'chanced': 0.25, 'chose': 0.25, 'feared': 0.25, 'had': 0.25},\n",
       " ('sitting', 'or'): {'standing': 1.0},\n",
       " ('or', 'standing'): {'as': 1.0},\n",
       " ('standing', 'as'): {'he': 1.0},\n",
       " ('he', 'chose'): {'END': 1.0},\n",
       " ('according', 'as'): {'he': 1.0},\n",
       " ('he', 'feared'): {'to': 1.0},\n",
       " ('to', 'risk'): {'END': 1.0},\n",
       " ('feared', 'to'): {'risk': 1.0},\n",
       " ('his', 'neck'): {'or': 1.0},\n",
       " ('neck', 'or'): {'thought': 1.0},\n",
       " ('or', 'thought'): {'to': 1.0},\n",
       " ('thought', 'to'): {'spare': 1.0},\n",
       " ('to', 'spare'): {'his': 0.5, 'them': 0.5},\n",
       " ('his', 'clothes'): {'END': 1.0},\n",
       " ('spare', 'his'): {'clothes': 1.0},\n",
       " ('he', 'never'): {'let': 0.3333333333333333,\n",
       "  'said': 0.3333333333333333,\n",
       "  'takes': 0.3333333333333333},\n",
       " ('never', 'let'): {'the': 0.5, 'them': 0.5},\n",
       " ('let', 'the'): {'lantern': 1.0},\n",
       " ('lantern', 'drop'): {'END': 1.0},\n",
       " ('the', 'lantern'): {'drop': 0.5, 'rattle': 0.5},\n",
       " ('and', 'some'): {'exclaimed': 1.0},\n",
       " ('some', 'exclaimed'): {'who': 1.0},\n",
       " ('exclaimed', 'who'): {'saw': 1.0},\n",
       " ('saw', 'afar'): {'END': 1.0},\n",
       " ('who', 'saw'): {'afar': 1.0},\n",
       " ('the', 'figures'): {'he': 1.0},\n",
       " ('figures', 'he'): {'described': 1.0},\n",
       " ('he', 'described'): {'with': 1.0},\n",
       " ('with', 'it'): {'END': 1.0},\n",
       " ('described', 'with'): {'it': 1.0},\n",
       " ('i', 'wonder'): {'what': 0.16666666666666666,\n",
       "  'if': 0.3333333333333333,\n",
       "  'END': 0.16666666666666666,\n",
       "  'where': 0.16666666666666666,\n",
       "  'why': 0.16666666666666666},\n",
       " ('wonder', 'what'): {'those': 1.0},\n",
       " ('what', 'those'): {'signals': 1.0},\n",
       " ('signals', 'are'): {'END': 1.0},\n",
       " ('those', 'signals'): {'are': 1.0},\n",
       " ('brown', 'makes'): {'at': 1.0},\n",
       " ('makes', 'at'): {'such': 1.0},\n",
       " ('such', 'an'): {'hour': 1.0},\n",
       " ('of', 'night'): {'END': 1.0},\n",
       " ...}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## HMM\n",
    "\n",
    "\n",
    "#### How is HMM different from MM\n",
    "\n",
    "*MM* \n",
    "\n",
    "- next state depends only on previous state \n",
    "\n",
    "- only revolves around 2 things primarily: probability of sequence & model training\n",
    "\n",
    "*HMM* \n",
    "\n",
    "- observed state $s_{k}$ only depends on state $s_{j}$, does not depend on state at any other time, does not depend on any other observation\n",
    "\n",
    "- 1 additional task to HMM is to get most likley \"hidden state\n",
    "\n",
    "- training a HMM is more computationally expensive and can test the limits of numerical accuracy\n",
    "\n",
    "\n",
    "3 parts: $\\pi$, A, B\n",
    "\n",
    "- $\\pi_{i}$ probability of starting at state i\n",
    "- A(i, j) probability of goin to state j from state i\n",
    "- B(j, k) probability of observing symbol k in state j\n",
    "\n",
    "\n",
    "**Doubly Embedded** Stochastic Processes (2 layers)\n",
    "\n",
    "1. Inner-most Layer = Markov Model\n",
    "2. Next Layer = Choose Observation\n",
    "\n",
    "#### Hidden States --> Neural Nets (layers)\n",
    "\n",
    "- number of hidden states is a hyperparameter\n",
    "- can get with cross-validation (T-Test can show which model is superior)\n",
    "\n",
    "**KEY:** Post cross-validation choose the hidden states with highest accuracy\n",
    "\n",
    "### Math\n",
    "\n",
    "$$p(x,z)=\\pi(z_{1})p(x_{1}|z_{1})\\prod_{t=2}^T p(z_{t}|z_{t-1})p(x_{t}|z_{t})$$\n",
    "\n",
    "Time Complexity: $O(TM^T)$ - exponential (nested for loops with T as the times M as the states)\n",
    "\n",
    "#### Forward-Backward Algo Approach (3 Steps)\n",
    "\n",
    "*Forward Algo*\n",
    "\n",
    "Time Complexity: $O(M^2T)$ -  polynomial instead of exponential\n",
    "\n",
    "**Define a new variable** $\\alpha(t,i)=p(x_{1},x_{2},...,x_{t},z_{t})=1$\n",
    "\n",
    "1) initialization step (t=1)\n",
    "$$\\alpha(t,i)=\\pi_{i}B(i,x_{t})$$\n",
    "\n",
    "2) Induction step (for every state and time t>1 up to T or steps after initialization step)\n",
    "$$\\alpha(t+1,j)=\\sum_{i=1}^M\\alpha(t,i)A(i,j)B(j,x_{t+})$$\n",
    "\n",
    "3) Termination step (t=T)\n",
    "$$p(x)=\\sum_{i=1}^M\\alpha(T,i)=\\sum_{i=1}^M p(x_{1},...,x{T},z_{T}=i)$$\n",
    "\n",
    "*Backward Algo*\n",
    "essentially the reverse of the Forward\n",
    "\n",
    "**Define**\n",
    "$$\\beta(t,i)=p(x_{t+1},...,x_{T}|z_{t}=i)$$\n",
    "\n",
    "1) Initialization step (t=T, $\\beta$ is 1 for all states)\n",
    "$$\\beta(T,i)=1$$\n",
    "\n",
    "2) Induction step (t<T down to 1)\n",
    "$$\\beta(t,i)=\\sum_{j=1}^M A(i,j)B(j,x_{t+1})\\beta(t+1,j)$$\n",
    "\n",
    "**PseudoCode**\n",
    "#fowards<br>\n",
    "`alpha = np.zeros((T, self.M))`<br>\n",
    "`alpha[0] = pi*B[:,x[0]] # initialization step`<br>\n",
    "`for t in range(1, T):`<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`alpha[t] = alpha[t-1].dot(A) * B[:, x[t]] # induction step`<br>\n",
    "`observation_prob = alpha[-1].sum() # termination`<br>\n",
    "\n",
    "#backwards<br>\n",
    "`beta = np.zeros((T, M))`<br>\n",
    "`beta[-1] = 1 # initialization step`<br>\n",
    "`for t in range(T-2, -1, -1):`<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`beta[t] = A.dot(B[:, x[t+1]] * beta[t+1]) # induction step`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viterbi Algorithm\n",
    "\n",
    "\"The most probable hidden states sequence given the sequence under the current model\"\n",
    "\n",
    "*like the forward algo but uses max instead of sum*\n",
    "\n",
    "Includes 2 new variables:\n",
    "\n",
    "$$\\delta(t,i)=max{p(z(1),...z(t)=i,x(1),...,x(t))}$$\n",
    "\n",
    "to keep track of states up to time t in state i\n",
    "\n",
    "$$\\psi(t,i)$$ \n",
    "\n",
    "#### 3 Steps\n",
    "\n",
    "1) Initialization \n",
    "\n",
    "$$\\delta(1,i)=\\pi_{i}B(i,x(1))$$\n",
    "$$\\psi(1,i)=0$$\n",
    "\n",
    "2) Recursion\n",
    "\n",
    "$$\\delta(t,j)=max_{1\\leq i\\leq M}{\\delta(t-1,i)A(i,j)}B(j,x(t))$$\n",
    "\n",
    "$$\\psi(t,j)=argmax_{1\\leq i\\leq M}{\\delta(t-1,i)A(i,j)}$$\n",
    "\n",
    "3) Termination\n",
    "\n",
    "- Find max probability\n",
    "$$p^* = max_{1\\leq i\\leq M}\\delta(T,i)$$\n",
    "- Best last state\n",
    "$$z(T)^* = argmax_{1\\leq i\\leq M}\\delta(T,i)$$\n",
    "- Previous best states\n",
    "$$z(t)^*=\\psi(t+1,z(t+1)^*)$$\n",
    "\n",
    "**PseudoCode**\n",
    "\n",
    "`#forward`<br>\n",
    "`delta = np.zeros((T, M))`<br>\n",
    "`psi = np.zeros((T, N))` <br>\n",
    "`delta[0] = pi * B[:, x[0]] # initialization`<br>\n",
    "`for t in range(1, T)\"`<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`for j in range(M):`<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`delta[t,j] = np.max(delta[t-1] * A[:, j]) * B[j, x[t]] # gives us the best probability overall`<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`psi[t,j] = np.argmax(delta[t-1] * A[:, j]) # gives us the best last state`<br>\n",
    "\n",
    "`#backward`<br>\n",
    "`states = np.zeros(T, dtype=np.int32)`<br>\n",
    "`states[T-1] = np.argmax(delta[T-1]]`<br>\n",
    "`for t in range(T-2, -1, -1):`<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`states[t] = psi[t+1, states[t+1]]`<br>\n",
    "`return states`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baum-Welch Algorithm\n",
    "\n",
    "- How to train an HMM\n",
    "- similar to Gaussian Mixture Models\n",
    "- Use Expectation-Maximization iterative algorithm\n",
    "\n",
    "**Define**\n",
    "$$\\phi(t,i,j)=p(z(t)=i,z(t+1)=j|x)$$\n",
    "\n",
    "$$\\gamma(t,i)=\\sum_{j=1}^M \\phi(t,i,j)$$\n",
    "\n",
    "*Summing over time*\n",
    "$$\\sum_{t=1}^{T-1}\\gamma(t,i)=E(\\text{num of transitions from state i})$$\n",
    "\n",
    "$$\\sum_{t=1}^{T-1}\\phi(t,i,j)=E(\\text{num of transitions from state i to state j})$$\n",
    "\n",
    "*Update*\n",
    "\n",
    "$$\\pi_{i}=\\gamma(1,i)$$\n",
    "\n",
    "$$A(i,j)=\\frac{\\sum_{t=1}^{T-1}\\phi(t,i,j)}{\\sum_{t=1}^{T-1}\\gamma(t,i)}$$\n",
    "\n",
    "$$B(i,k)=\\frac{\\sum_{t=1}^{T-1}\\gamma(t,i)\\text{ if } x(t)=k,\\text{else}\\ 0}{\\sum_{t=1}^{T-1}\\gamma(t,i)}$$\n",
    "\n",
    "**PseudoCode**\n",
    "\n",
    "`pi = np.sum((alphas[n][0] * betas[n][0]) / P[n] for n in range(N)) / N # pi`<br>\n",
    "\n",
    "`# A update`<br>\n",
    "`a_num = np.zeros((M, M))`<br>\n",
    "`for n in range(N):`<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`x = X[n]`<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`T = len(x)`<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`den1 += (alphas[n][:-1] * betas[n][:-1]).sum(axis=0, keepdims=True).T / P[n]`<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`a_num_n = np.zeros((M, M))`<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`for i in range(M):`<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`for j in range(M):`<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`for t in range(T-1):`<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`a_num_n[i, j] += alpha[n][t, i] * betas[n][t+1, j] * A[i, j] * B[j, x[t+1]]`<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`a_num += a_num_n / P[n]`<br>\n",
    "`A =a_num /den1`<br>\n",
    "\n",
    "`# B update`<br>\n",
    "`b_num = np.zeros((M, V))`<br>\n",
    "`for n in range(N):`<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`x = X[n]`<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`T = len(x)`<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`den2 += (alphas[n] * betas[n]).sum(axis=0, keepdims=True).T / P[n]`<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`b_num_n = np.zeros((M, V))`<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`for i in range(M):`<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`for j in range(V):`<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`for t in range(T):`<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`if x[t] == j:`<br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`b_num[i, j] += alphas[n][t][i] * betas[n][t][i]`<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`b_num += b_num_n / P[n]`<br>\n",
    "`B =a_num /den2`<br>\n",
    "\n",
    "#### Multiple Observations\n",
    "\n",
    "- variable length sequences like in text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coin Toss Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T20:30:27.047658Z",
     "start_time": "2019-04-29T20:30:27.008973Z"
    }
   },
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self, M):\n",
    "        self.M = M # number of hidden states\n",
    "    \n",
    "    def fit(self, X, max_iter=30):\n",
    "        t0 = datetime.now()\n",
    "        np.random.seed(123)\n",
    "        # train the HMM model using the Baum-Welch algorithm\n",
    "        # a specific instance of the expectation-maximization algorithm\n",
    "\n",
    "        # determine V, the vocabulary size\n",
    "        # assume observables are already integers from 0..V-1\n",
    "        # X is a jagged array of observed sequences\n",
    "        V = max(max(x) for x in X) + 1\n",
    "        N = len(X)\n",
    "\n",
    "        self.pi = np.ones(self.M) / self.M # initial state distribution\n",
    "        self.A = random_normalized(self.M, self.M) # state transition matrix\n",
    "        self.B = random_normalized(self.M, V) # output distribution\n",
    "\n",
    "        print(\"initial A:\", self.A)\n",
    "        print(\"initial B:\", self.B)\n",
    "\n",
    "        costs = []\n",
    "        for it in range(max_iter):\n",
    "            if it % 10 == 0:\n",
    "                print(\"it:\", it)\n",
    "            alphas = []\n",
    "            betas = []\n",
    "            P = np.zeros(N)\n",
    "            for n in range(N):\n",
    "                x = X[n]\n",
    "                T = len(x)\n",
    "                alpha = np.zeros((T, self.M))\n",
    "                alpha[0] = self.pi*self.B[:,x[0]]\n",
    "                for t in range(1, T):\n",
    "                    tmp1 = alpha[t-1].dot(self.A) * self.B[:, x[t]]\n",
    "                    # tmp2 = np.zeros(self.M)\n",
    "                    # for i in range(self.M):\n",
    "                    #     for j in range(self.M):\n",
    "                    #         tmp2[j] += alpha[t-1,i] * self.A[i,j] * self.B[j, x[t]]\n",
    "                    # print \"diff:\", np.abs(tmp1 - tmp2).sum()\n",
    "                    alpha[t] = tmp1\n",
    "                P[n] = alpha[-1].sum()\n",
    "                alphas.append(alpha)\n",
    "\n",
    "                beta = np.zeros((T, self.M))\n",
    "                beta[-1] = 1\n",
    "                for t in range(T - 2, -1, -1):\n",
    "                    beta[t] = self.A.dot(self.B[:, x[t+1]] * beta[t+1])\n",
    "                betas.append(beta)\n",
    "\n",
    "            # print \"P:\", P\n",
    "            # break\n",
    "            assert(np.all(P > 0))\n",
    "            cost = np.sum(np.log(P))\n",
    "            costs.append(cost)\n",
    "\n",
    "            # now re-estimate pi, A, B\n",
    "            self.pi = np.sum((alphas[n][0] * betas[n][0])/P[n] for n in range(N)) / N\n",
    "            # print \"self.pi:\", self.pi\n",
    "            # break\n",
    "\n",
    "            den1 = np.zeros((self.M, 1))\n",
    "            den2 = np.zeros((self.M, 1))\n",
    "            a_num = 0\n",
    "            b_num = 0\n",
    "            for n in range(N):\n",
    "                x = X[n]\n",
    "                T = len(x)\n",
    "                # print \"den shape:\", den.shape\n",
    "                # test = (alphas[n][:-1] * betas[n][:-1]).sum(axis=0, keepdims=True).T\n",
    "                # print \"shape (alphas[n][:-1] * betas[n][:-1]).sum(axis=0): \", test.shape\n",
    "                den1 += (alphas[n][:-1] * betas[n][:-1]).sum(axis=0, keepdims=True).T / P[n]\n",
    "                den2 += (alphas[n] * betas[n]).sum(axis=0, keepdims=True).T / P[n]\n",
    "\n",
    "                # tmp2 = np.zeros((self.M, 1))\n",
    "                # for i in range(self.M):\n",
    "                #     for t in range(T-1):\n",
    "                #         tmp2[i] += alphas[n][t,i] * betas[n][t,i]\n",
    "                # tmp2 /= P[n]\n",
    "                # # print \"diff:\", np.abs(tmp1 - tmp2).sum()\n",
    "                # den += tmp1\n",
    "\n",
    "                # numerator for A\n",
    "                a_num_n = np.zeros((self.M, self.M))\n",
    "                for i in range(self.M):\n",
    "                    for j in range(self.M):\n",
    "                        for t in range(T-1):\n",
    "                            a_num_n[i,j] += alphas[n][t,i] * self.A[i,j] * self.B[j, x[t+1]] * betas[n][t+1,j]\n",
    "                a_num += a_num_n / P[n]\n",
    "\n",
    "                # numerator for B\n",
    "                # b_num_n = np.zeros((self.M, V))\n",
    "                # for i in range(self.M):\n",
    "                #     for j in range(V):\n",
    "                #         for t in range(T):\n",
    "                #             if x[t] == j:\n",
    "                #                 b_num_n[i,j] += alphas[n][t][i] * betas[n][t][i]\n",
    "                b_num_n2 = np.zeros((self.M, V))\n",
    "                for i in range(self.M):\n",
    "                    for t in range(T):\n",
    "                        b_num_n2[i,x[t]] += alphas[n][t,i] * betas[n][t,i]\n",
    "                b_num += b_num_n2 / P[n]\n",
    "            # tmp1 = a_num / den1\n",
    "            # tmp2 = np.zeros(a_num.shape)\n",
    "            # for i in range(self.M):\n",
    "            #     for j in range(self.M):\n",
    "            #         tmp2[i,j] = a_num[i,j] / den1[i]\n",
    "            # print \"diff:\", np.abs(tmp1 - tmp2).sum()\n",
    "            # print \"tmp1:\", tmp1\n",
    "            # print \"tmp2:\", tmp2\n",
    "            self.A = a_num / den1\n",
    "            self.B = b_num / den2\n",
    "            # print \"P:\", P\n",
    "            # break\n",
    "        print(\"A:\", self.A)\n",
    "        print(\"B:\", self.B)\n",
    "        print(\"pi:\", self.pi)\n",
    "\n",
    "        print(\"Fit duration:\", (datetime.now() - t0))\n",
    "\n",
    "        plt.plot(costs)\n",
    "        plt.show()\n",
    "\n",
    "    def likelihood(self, x):\n",
    "        # returns log P(x | model)\n",
    "        # using the forward part of the forward-backward algorithm\n",
    "        T = len(x)\n",
    "        alpha = np.zeros((T, self.M))\n",
    "        alpha[0] = self.pi*self.B[:,x[0]]\n",
    "        for t in range(1, T):\n",
    "            alpha[t] = alpha[t-1].dot(self.A) * self.B[:, x[t]]\n",
    "        return alpha[-1].sum()\n",
    "\n",
    "    def likelihood_multi(self, X):\n",
    "        return np.array([self.likelihood(x) for x in X])\n",
    "\n",
    "    def log_likelihood_multi(self, X):\n",
    "        return np.log(self.likelihood_multi(X))\n",
    "\n",
    "    def get_state_sequence(self, x):\n",
    "        # returns the most likely state sequence given observed sequence x\n",
    "        # using the Viterbi algorithm\n",
    "        T = len(x)\n",
    "        delta = np.zeros((T, self.M))\n",
    "        psi = np.zeros((T, self.M))\n",
    "        delta[0] = self.pi*self.B[:,x[0]]\n",
    "        for t in range(1, T):\n",
    "            for j in range(self.M):\n",
    "                delta[t,j] = np.max(delta[t-1]*self.A[:,j]) * self.B[j, x[t]]\n",
    "                psi[t,j] = np.argmax(delta[t-1]*self.A[:,j])\n",
    "\n",
    "        # backtrack\n",
    "        states = np.zeros(T, dtype=np.int32)\n",
    "        states[T-1] = np.argmax(delta[T-1])\n",
    "        for t in range(T-2, -1, -1):\n",
    "            states[t] = psi[t+1, states[t+1]]\n",
    "        return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T20:30:27.723132Z",
     "start_time": "2019-04-29T20:30:27.716328Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_coin():\n",
    "    X = []\n",
    "    for line in open('./data/coin_data.txt'):\n",
    "        x = [1 if e == 'H' else 0 for e in line.rstrip()]\n",
    "        X.append(x)\n",
    "        \n",
    "    hmm = HMM(2)\n",
    "    hmm.fit(X)\n",
    "    L = hmm.log_likelihood_multi(X).sum()\n",
    "    print(f\"LL w/ fitted params: {L}\")\n",
    "    \n",
    "    hmm.pi = np.array([0.5, 0.5])\n",
    "    hmm.A = np.array([[0.1, 0.9], [0.8, 0.2]])\n",
    "    hmm.B = np.array([[0.6, 0.4], [0.3, 0.7]])\n",
    "    L = hmm.log_likelihood_multi(X).sum()\n",
    "    print(f\"LL w/ true params: {L}\")\n",
    "    \n",
    "    # try Viterbi\n",
    "    print(f\"Best state sequence for: {X[0]}\")\n",
    "    print(hmm.get_state_sequence(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T20:30:50.438191Z",
     "start_time": "2019-04-29T20:30:49.608351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial A: [[0.7087962  0.2912038 ]\n",
      " [0.29152056 0.70847944]]\n",
      "initial B: [[0.62969057 0.37030943]\n",
      " [0.58883752 0.41116248]]\n",
      "it: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marktblack/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:60: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it: 10\n",
      "it: 20\n",
      "A: [[0.70386662 0.29613338]\n",
      " [0.28712763 0.71287237]]\n",
      "B: [[0.54419694 0.45580306]\n",
      " [0.53723247 0.46276753]]\n",
      "pi: [0.50695647 0.49304353]\n",
      "Fit duration: 0:00:00.653991\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD9CAYAAABJGYveAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAG0lJREFUeJzt3X2MXNd93vHvs8s3iXqzU9qSuGSlWhQEya3pdEDYhdHItlSykkCGQpjQjQIbicwgoBHVQaGUVdDEBgioTasKESLbtCJDhaTQROy1CNGWK8ZiFQG2GNKibJJrqhvLhsioIl2b8A4VLjM7v/4xZ3bvzs6d2d3L9XJ4nw+82Lnnbc7dMe9P95w75ygiMDMza6dvvjtgZmYXLgcJMzPL5SBhZma5HCTMzCyXg4SZmeVykDAzs1yFgoSkTZKOSKpLqrTkbZM0LOmYpLUpbYmk/ZJeTfU+06bNP5NULdIvMzM7PxYUrH8YuBv4QjZR0s3AZuAW4Fpgr6QbgVHgIxFRlbQQeEnSNyLiO6leBXhHwT6Zmdl5UuhOIiKGIuJYm6wNwM6IGI2I14FhYE00NO8SFqafAJDUD/wpcH+RPpmZ2fkzV3MSy4E3MsfHUxqS+iUdAk4Cz0fEy6nMp4DdEfHmHPXJzMxmqOtwk6S9wNVtsh6IiGdm+oYRMQaslnQVMCjpvcBPgU3ArdNpQ9IWYAvA0qVL/+VNN900026YmZXawYMHfxIRy7qV6xokIuK2Wbz/CWBF5nggpWXbPS3pBWAdMATcAAxLArhU0nBE3JDTpx3ADoBKpRIHDhyYRRfNzMpL0o+nU26uhpt2A5slLZZ0PbAK2C9pWbqDQNIlwO3ADyJiT0RcHRHXRcR1wNt5AcLMzH5xCj3dJGkj8AiwDNgj6VBErI2II5J2AUeBGrA1IsYkXQM8kSap+4BdEfFswXMwM7M5ol5fKtzDTWZmMyfpYERUupXzN67NzCyXg4SZmeVykDAzs1wOEmZmlqvo2k3WYyKCekz8rqcHF+oRRDoOIOoQTJSNVIbG/8bLB1CvR2o7Uz/7O5Ubz49G281nJrLHk+sCTK4/Oa9Rj2x+tt1MW7R9z4m/ycTrZs3WMum92tSd/PfN9Ct7nOlTtt547Zx6k+vktN2mAzE1aWpf25Rpn5f/cMvUetEhr3v91ja6lW1fbmrBvLrT7VP7utPv57QfD5rhg0Qf/1fX8UuXLZ5RnZlykOjiXK3O5//333H67X+kHsFYPRiLoF6f/LoeTEpvXoCbdSIYLx8xUSZ7sW6Wa9abeE3L8dS69Xqb8kwu0+MPspmVQuP7xNOzfvVyB4n59v0Tp3no+ddYsrCPRf199PeJ/j7Rp4nffX3QL9HXJ/rbpGs8DfokFvT3sXhBo3wzrU+g9Lu/T+l1SodUdqK8NLWuNNEPwaQyyrQvUtm+xv8bm/nZPGXeu/kaNdodby+9pqWcWtpJVRv1aP4jmGgjW6ZZl3Z5mTo0y43nTfwNJt4j/31SzqR/kO3S1eZ9JspOTSe9z0Tu5Hazx1PeN6deu7qZ05uU37ZMm7Zby7a20Vp4Sp/btN0+r7Xe1CvgTC6K7cpOt828t2ntf6ey03mfvDZ7lYNEFz8/WwPg6U9+gF9e6VXMzaxcPHHdRTUFicsXO56aWfk4SHRxZrQRJJY6SJhZCTlIdFFNQeKyJQ4SZlY+DhJdjKThpqWLHCTMrHwcJLo4M1rj0kX9408CmZmViYNEF9XRGpd5PsLMSspBoosRBwkzKzEHiS7OjNY8aW1mpeUg0UX1rO8kzKy8HCS6qI7W/B0JMyutQkFC0iZJRyTVJVVa8rZJGpZ0TNLalLZE0n5Jr6Z6n8mUl6Ttkl6TNCTp94v07Xypjtb8bWszK62iV7/DwN3AF7KJkm4GNgO3ANcCeyXdCIwCH4mIqqSFwEuSvhER3wE+AawAboqIuqR3FezbeVH1nISZlVihq19EDEHbFQ83ADsjYhR4XdIwsCYivg1UU5mF6ae5gPXvAf8uIuqp7ZNF+nY+RARnPNxkZiU2V3MSy4E3MsfHUxqS+iUdAk4Cz0fEy6nMe4DfkHRA0jckrZqjvk3baK3OP46FJ67NrLS6BglJeyUdbvOzYTZvGBFjEbEaGADWSHpvyloMnI2ICvBF4PEOfdqSgsmBU6dOzaYb09Jct+lyDzeZWUl1vfpFxG2zaPcEjfmFpoGUlm33tKQXgHU05jaOA19N2YPAlzr0aQewA6BSqczZfmvjK8B63SYzK6m5Gm7aDWyWtFjS9cAqYL+kZZKuApB0CXA78INU52vAh9PrXwFem6O+TVtzcT9PXJtZWRW6+knaCDwCLAP2SDoUEWsj4oikXcBRoAZsjYgxSdcAT0jqpxGgdkXEs6m5B4GnJH2axuT2vUX6dj6MDzd5TsLMSqro002DNIaG2uVtB7a3pH0PeH9O+dPAnUX6c755wyEzKzt/47oDbzhkZmXnINHBiPe3NrOSc5DowMNNZlZ2DhIdVEdrSHDpov757oqZ2bxwkOhgJC0T3mbZETOzUnCQ6OCMd6Uzs5JzkOjA+1ubWdk5SHTgZcLNrOwcJDrwnYSZlZ2DRAfe39rMys5BogPfSZhZ2TlIdFD1rnRmVnIOEjkigupozRsOmVmpOUjkePvcGBF4uMnMSs1BIofXbTIzc5DINeL9rc3MHCTyVM96f2szMweJHGe84ZCZWbEgIWmTpCOS6pIqLXnbJA1LOiZpbUpbImm/pFdTvc9kyn9U0nclHZL0kqQbivStqOZwkyeuzazMit5JHAbuBl7MJkq6GdgM3AKsAx6V1A+MAh+JiPcBq4F1kj6Qqn0O+M2IWA08DfxRwb4V0hxucpAwszIrFCQiYigijrXJ2gDsjIjRiHgdGAbWREM1lVmYfqLZHHBFen0l8PdF+lbUmXMebjIzm6sr4HLgO5nj4ymNdEdxELgB+POIeDmVuRf4uqR/AH4OfIB5NOI7CTOz7ncSkvZKOtzmZ8Ns3jAixtKQ0gCwRtJ7U9angTsiYgD4EvBQhz5tkXRA0oFTp07NphtdVUdrLOgTixd4bt/MyqvrfyZHxG2zaPcEsCJzPJDSsu2elvQCjXmJt4D3Ze4qvgw816FPO4AdAJVKJfLKFXEm7SXhrUvNrMzm6j+TdwObJS2WdD2wCtgvaZmkqwAkXQLcDvwA+BlwpaQbU/3bgaE56tu0eJlwM7OCcxKSNgKPAMuAPZIORcTaiDgiaRdwFKgBWyNiTNI1wBNpXqIP2BURz6a2Pgl8RVKdRtD47SJ9K2rEy4SbmRULEhExCAzm5G0HtrekfQ94/0zbmg9nHCTMzPyN6zze39rMzEEiV/WsNxwyM3OQyFEdrXG5g4SZlZyDRA7vb21m5iDR1lg9ePvcmIebzKz0HCTaaK7b5A2HzKzsHCTa8AqwZmYNDhJteH9rM7MGB4k2RrwrnZkZ4CDRVnO4yY/AmlnZOUi04eEmM7MGB4k2vL+1mVmDg0Qb48NNnpMws5JzkGjDw01mZg0OEm1UR2ssXtDHwn7/ecys3HwVbGNktOahJjMzHCTaOjPqZcLNzMBBoi3vb21m1lAoSEjaJOmIpLqkSkveNknDko5JWtuS1y/pFUnPZtKul/RyqvNlSYuK9K0I729tZtZQ9E7iMHA38GI2UdLNwGbgFmAd8Kik/kyR+4Chlrb+C/A/IuIG4GfA7xTs26x5f2szs4ZCQSIihiLiWJusDcDOiBiNiNeBYWANgKQB4E7gsWZhSQI+AvxVSnoC+NUifSvC+1ubmTXM1ZzEcuCNzPHxlAbwMHA/UM/k/xJwOiJqbcr/wnl/azOzhq5XQkl7gavbZD0QEc/M5M0k3QWcjIiDkm6dSd2WdrYAWwBWrlw522ZyeX9rM7OGrlfCiLhtFu2eAFZkjgdS2npgvaQ7gCXAFZKeBH4LuErSgnQ30Syf16cdwA6ASqUSs+hfrnO1OqO1uuckzMyYu+Gm3cBmSYslXQ+sAvZHxLaIGIiI62hMbH8rIu6JiABeAH4t1f84MKO7lPPFS3KYmU0o+gjsRknHgQ8CeyR9EyAijgC7gKPAc8DWiBjr0twfAn8gaZjGHMVfFOnbbFW94ZCZ2bhCV8KIGAQGc/K2A9s71N0H7Msc/5D0BNR8agYJz0mYmfkb11NUPdxkZjbOQaKFh5vMzCY4SLTw/tZmZhMcJFp4uMnMbIKDRIszHm4yMxvnINFiJA03LV3kIGFm5iDRojpa49JF/fT3ab67YmY27xwkWniZcDOzCQ4SLUa8TLiZ2TgHiRbeutTMbIKDRAsPN5mZTXCQaFF1kDAzG+cg0WLEw01mZuMcJFqcOeeJazOzJgeJjIjwxLWZWYaDRMZorU6tHl63ycwscZDIGN9wyMNNZmaAg8QkzWXCPdxkZtZQdI/rTZKOSKpLqrTkbZM0LOmYpLUtef2SXpH0bCbtqVT2sKTHJS0s0rfZ8DLhZmaTFb2TOAzcDbyYTZR0M7AZuAVYBzwqqT9T5D5gqKWtp4CbgH8OXALcW7BvM+b9rc3MJisUJCJiKCKOtcnaAOyMiNGIeB0YBtYASBoA7gQea2nr65EA+4GBIn2bjfHhJs9JmJkBczcnsRx4I3N8PKUBPAzcD9TbVUzDTL8FPDdHfct15pyHm8zMsrpeDSXtBa5uk/VARDwzkzeTdBdwMiIOSro1p9ijwIsR8Tcd2tkCbAFYuXLlTLrQ0Yj3tzYzm6Tr1TAibptFuyeAFZnjgZS2Hlgv6Q5gCXCFpCcj4h4ASX8MLAN+t0ufdgA7ACqVSsyif21VvXWpmdkkczXctBvYLGmxpOuBVcD+iNgWEQMRcR2Nie1vZQLEvcBa4GMR0XYoaq6dGa3RJ7hkYX/3wmZmJVD0EdiNko4DHwT2SPomQEQcAXYBR2nMLWyNiLEuzX0eeDfwbUmHJP3nIn2bjZGzNZYuXoDkrUvNzGAaw02dRMQgMJiTtx3Y3qHuPmBf5njex3i8TLiZ2WT+xnWGNxwyM5vMQSKj6v2tzcwmcZDI8IZDZmaTOUhkeLjJzGwyB4kMT1ybmU3mIJFRTY/AmplZg4NEEhFUz9W84ZCZWYaDRPL2uTEivOGQmVmWg0TiDYfMzKZykEi8v7WZ2VQOEon3tzYzm8pBIvFwk5nZVA4SyfheEg4SZmbjHCSS5nCT5yTMzCY4SCQebjIzm8pBIvFwk5nZVA4SSXW0xsJ+sXiB/yRmZk2+IiZVb11qZjZF0T2uN0k6IqkuqdKSt03SsKRjkta25PVLekXSs23a/DNJ1SL9mg0vE25mNlXRO4nDwN3Ai9lESTcDm4FbgHXAo5L6M0XuA4ZaG0uB5h0F+zQrIw4SZmZTFAoSETEUEcfaZG0AdkbEaES8DgwDawAkDQB3Ao9lK6Qg8qfA/UX6NFtV70pnZjbFXM1JLAfeyBwfT2kAD9MIBPWWOp8CdkfEm3PUp47OnPP+1mZmrbpeFSXtBa5uk/VARDwzkzeTdBdwMiIOSro1k34tsAm4NadqaztbgC0AK1eunEkXclXP1lj5zkvPS1tmZheLrkEiIm6bRbsngBWZ44GUth5YL+kOYAlwhaQngb8EbgCG09NFl0oajogbcvq0A9gBUKlUYhb9m8JzEmZmU83VVXE38LSkh4BrgVXA/oj4NrANIN1J/IeIuCfVGb9bkVTNCxBzxU83mZlNVfQR2I2SjgMfBPZI+iZARBwBdgFHgeeArRExVrSzc2WsHrx9bsxzEmZmLQpdFSNiEBjMydsObO9Qdx+wLyfvsiL9mikvyWFm1p6/cU1jqAkcJMzMWjlIkLmT8HCTmdkkDhLAyFkvE25m1o6DBBPDTZc7SJiZTeIggTccMjPL4yCBn24yM8vjIIH3tzYzy+MggYebzMzyOEjQmLhevKCPhf3+c5iZZfmqSGNxPw81mZlN5SDBxP7WZmY2mYMEXgHWzCyPgwTeS8LMLI+DBN7f2swsj4ME3t/azCyPgwS+kzAzy+MggeckzMzylD5InKvVOVerO0iYmbVRdI/rTZKOSKpLqrTkbZM0LOmYpLUtef2SXpH0bCZNkrZLek3SkKTfL9K36TrjDYfMzHIVvTIeBu4GvpBNlHQzsBm4BbgW2CvpxogYS0XuA4aAKzLVPgGsAG6KiLqkdxXs27R43SYzs3yF7iQiYigijrXJ2gDsjIjRiHgdGAbWAEgaAO4EHmup83vAZyOinto+WaRv01X1hkNmZrnmak5iOfBG5vh4SgN4GLgfqLfUeQ/wG5IOSPqGpFVz1LdJvL+1mVm+rkFC0l5Jh9v8bJjpm0m6CzgZEQfbZC8GzkZEBfgi8HiHdrakYHLg1KlTM+3GJFXvb21mlqvrlTEibptFuydozC80DaS09cB6SXcAS4ArJD0ZEffQuNv4aio/CHypQ592ADsAKpVKzKJ/4zzcZGaWb66Gm3YDmyUtlnQ9sArYHxHbImIgIq6jMbH9rRQgAL4GfDi9/hXgtTnq2yQebjIzy1foyihpI/AIsAzYI+lQRKyNiCOSdgFHgRqwNfNkU54HgackfRqoAvcW6dt0ebjJzCxfoStjRAzSGBpql7cd2N6h7j5gX+b4NI2nnn6hxh+BXeQgYWbWqvTfuK6O1li6qJ/+Ps13V8zMLjgOEt6Vzswsl4OElwk3M8vlIHG25sdfzcxyOEiMerjJzCxP6YPEGe8lYWaWq/RBYuSs5yTMzPKUPkhUfSdhZpar1EEiIjzcZGbWQamDxGitTq0enrg2M8tR6iAxktZtutxzEmZmbZU6SIzvb+07CTOztkodJLy/tZlZZ6UOEuPDTQ4SZmZtlTpInPGGQ2ZmHZU6SHi4ycyss1IHiRHvb21m1lGpg4SHm8zMOit1kKierdEnuGRh/3x3xczsglQoSEjaJOmIpLqkSkveNknDko5JWtuS1y/pFUnPZtI+Kum7kg5JeknSDUX6Nh3NZcIlb11qZtZO0TuJw8DdwIvZREk3A5uBW4B1wKOSsv+5fh8w1NLW54DfjIjVwNPAHxXsW1fVUW84ZGbWSaEgERFDEXGsTdYGYGdEjEbE68AwsAZA0gBwJ/BYa3PAFen1lcDfF+nbdHh/azOzzubqCrkc+E7m+HhKA3gYuB+4vKXOvcDXJf0D8HPgA3mNS9oCbAFYuXLlrDt5xvtbm5l11PVOQtJeSYfb/GyY6ZtJugs4GREH22R/GrgjIgaALwEP5bUTETsiohIRlWXLls20G+NGznqZcDOzTrpeISPitlm0ewJYkTkeSGnrgfWS7gCWAFdIepJGgHhfRLycyn8ZeG4W7zsj1dEa11y5ZK7fxsysZ83VI7C7gc2SFku6HlgF7I+IbRExEBHX0ZjY/lZE3AP8DLhS0o2p/u1Mndg+77zhkJlZZ4WukJI2Ao8Ay4A9kg5FxNqIOCJpF3AUqAFbI2Isr52IqEn6JPAVSXUaQeO3i/RtOqre39rMrKNCV8iIGAQGc/K2A9s71N0H7JtOW3MhIqie852EmVknpf3G9dvnxojwhkNmZp2UNkhUvW6TmVlXpQ0SzQ2HfCdhZpavtEHC+1ubmXVX2iBRdZAwM+uqtEGiOdzktZvMzPKVNkg0h5su98S1mVmu0gYJDzeZmXVX+iDh4SYzs3ylDhIL+8XiBaX9E5iZdVXaK2Q1LRPurUvNzPKVN0iMelc6M7NuSh0kPGltZtZZaa+Sq1dcxXuWXTbf3TAzu6CVNkhs/fAN890FM7MLXmmHm8zMrDsHCTMzy+UgYWZmuQoFCUmbJB2RVJdUacnbJmlY0jFJazPpP5L0fUmHJB3IpL9T0vOS/k/6/Y4ifTMzs+KK3kkcBu4GXswmSroZ2AzcAqwDHpXUnyny4YhYHRHZwPIfgb+OiFXAX6djMzObR4WCREQMRcSxNlkbgJ0RMRoRrwPDwJouzW0AnkivnwB+tUjfzMysuLmak1gOvJE5Pp7SAAL4X5IOStqSKfPuiHgzvf6/wLvzGpe0RdIBSQdOnTp1PvttZmYZXb8nIWkvcHWbrAci4plZvOeHIuKEpHcBz0v6QURMGq6KiJAUeQ1ExA5gB0ClUsktZ2ZmxXQNEhFx2yzaPQGsyBwPpDQiovn7pKRBGsNQLwJvSbomIt6UdA1wcjpvdPDgwZ9I+vEs+gjwT4CfzLLuhepiOyefz4XvYjuni+18oP05/dPpVJyrb1zvBp6W9BBwLbAK2C9pKdAXESPp9b8BPpup83HgwfR7WncpEbFstp2UdKBl8rznXWzn5PO58F1s53SxnQ8UO6dCQULSRuARYBmwR9KhiFgbEUck7QKOAjVga0SMSXo3MJiW514APB0Rz6XmHgR2Sfod4MfArxfpm5mZFVcoSETEIDCYk7cd2N6S9kPgfTnl/x/w0SL9MTOz86vs37jeMd8dmAMX2zn5fC58F9s5XWznAwXOSRF+OMjMzNor+52EmZl1UNogIWldWldqWFLPLwGStyZWL5H0uKSTkg5n0np2Ta+c8/kTSSfS53RI0h3z2ceZkLRC0guSjqY12+5L6b38GeWdU09+TpKWSNov6dV0Pp9J6ddLejld774sadG02yzjcFNaR+o14HYa3wb/W+BjEXF0XjtWgKQfAZWI6NnnuyX9a6AK/M+IeG9K+6/ATyPiwRTM3xERfzif/ZyunPP5E6AaEf9tPvs2G+n7S9dExHclXQ4cpLF8zifo3c8o75x+nR78nNR4dHRpRFQlLQReAu4D/gD4akTslPR54NWI+Nx02izrncQaYDgifhgR54CdNNaOsnmUvnn/05bknl3TK+d8elZEvBkR302vR4AhGsvt9PJnlHdOPSkaqulwYfoJ4CPAX6X0GX1GZQ0SndaW6lV5a2L1ummv6dVDPiXpe2k4qmeGZrIkXQe8H3iZi+Qzajkn6NHPSVK/pEM0Vq14Hvg74HRE1FKRGV3vyhokLkYfiohfBv4tsDUNdVxUojE22uvjo58D3gOsBt4E/vv8dmfmJF0GfAX49xHx82xer35Gbc6pZz+niBiLiNU0lkNaA9xUpL2yBonctaV6VXZNLBpfcOy2NHuveCuNGzfHj6e1pteFKiLeSv+I68AX6bHPKY1zfwV4KiK+mpJ7+jNqd069/jkBRMRp4AXgg8BVkppfnp7R9a6sQeJvgVVpxn8RjQ2Sds9zn2ZN0tI06UZmTazDnWv1jOaaXjCDNb0uVM2LabKRHvqc0qToXwBDEfFQJqtnP6O8c+rVz0nSMklXpdeX0Hg4Z4hGsPi1VGxGn1Epn24CSI+0PQz0A4+nZUR6kqR/xsTyKM01sXrufCT9JXArjRUr3wL+GPgasAtYSVrTKyJ6YjI453xupTGEEcCPgN/NjOdf0CR9CPgb4PtAPSX/Jxpj+L36GeWd08fowc9J0r+gMTHdT+MmYFdEfDZdI3YC7wReAe6JiNFptVnWIGFmZt2VdbjJzMymwUHCzMxyOUiYmVkuBwkzM8vlIGFmZrkcJMzMLJeDhJmZ5XKQMDOzXP8fRqC5aVRRgKgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LL w/ fitted params: -1034.7557547352071\n",
      "LL w/ true params: -1059.7229160265022\n",
      "Best state sequence for: [0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1]\n",
      "[0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    fit_coin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Underflow Problem\n",
    "\n",
    "\"Multiplying by very long sequence of small numbers --> vanishing alphas\"\n",
    "\n",
    "#### Scaling Forward\n",
    "\n",
    "Create a scale factor $c(t), t=1,..., T$\n",
    "\n",
    "1) Initialize \n",
    "\n",
    "$$\\alpha'=\\pi_{i}B(j,x(1))=\\alpha(1,i)$$\n",
    "\n",
    "Define a scale\n",
    "\n",
    "$$c(t)=\\sum_{i=1}^M\\alpha'(t,i)$$\n",
    "$$\\hat{\\alpha}(t,i)=frac{\\alpha'(t,i)}{c(t)}$$\n",
    "\n",
    "Scale temporary variable\n",
    "\n",
    "$$\\hat{\\alpha}(1,i)=\\frac{\\pi_{i}B(j,x(1))}{c(1)}$$\n",
    "\n",
    "2) Induction Step\n",
    "\n",
    "Temporary variable\n",
    "\n",
    "$$\\alpha'(t,j)=\\sum_{t=1}^M\\hat{\\alpha}(t-1,i)A(i,j)B(j,x(t))$$\n",
    "\n",
    "scale as before\n",
    "\n",
    "$$\\hat{\\alpha}(t,i)=\\frac{\\alpha'(t,i)}{c(t)}$$\n",
    "\n",
    "3) Termination\n",
    "\n",
    "$$p(x)=\\prod_{t=1}^T c(t)$$\n",
    "\n",
    "Use log probabilities\n",
    "\n",
    "#### Scaling Backward\n",
    "\n",
    "1) Initialize\n",
    "\n",
    "$$\\hat(\\beta}(T,i)=1$$\n",
    "\n",
    "2) Induction\n",
    "\n",
    "$$\\hat{\\beta}(t,i)=\\frac{\\sum_{j=1}^N A(i,j)B(j,x(t+1))\\hat{\\beta}(t+1,j)}{c(t+1)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T22:10:51.962964Z",
     "start_time": "2019-04-29T22:10:51.903314Z"
    }
   },
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self, M):\n",
    "        self.M = M # number of hidden states\n",
    "    \n",
    "    def fit(self, X, max_iter=30):\n",
    "        np.random.seed(123)\n",
    "        # train the HMM model using the Baum-Welch algorithm\n",
    "        # a specific instance of the expectation-maximization algorithm\n",
    "\n",
    "        # determine V, the vocabulary size\n",
    "        # assume observables are already integers from 0..V-1\n",
    "        # X is a jagged array of observed sequences\n",
    "        V = max(max(x) for x in X) + 1\n",
    "        N = len(X)\n",
    "\n",
    "        self.pi = np.ones(self.M) / self.M # initial state distribution\n",
    "        self.A = random_normalized(self.M, self.M) # state transition matrix\n",
    "        self.B = random_normalized(self.M, V) # output distribution\n",
    "\n",
    "        print(\"initial A:\", self.A)\n",
    "        print(\"initial B:\", self.B)\n",
    "\n",
    "        costs = []\n",
    "        for it in range(max_iter):\n",
    "            if it % 10 == 0:\n",
    "                print(\"it:\", it)\n",
    "            # alpha1 = np.zeros((N, self.M))\n",
    "            alphas = []\n",
    "            betas = []\n",
    "            scales = []\n",
    "            logP = np.zeros(N)\n",
    "            for n in range(N):\n",
    "                x = X[n]\n",
    "                T = len(x)\n",
    "                scale = np.zeros(T)\n",
    "                # alpha1[n] = self.pi*self.B[:,x[0]]\n",
    "                alpha = np.zeros((T, self.M))\n",
    "                alpha[0] = self.pi*self.B[:,x[0]]\n",
    "                scale[0] = alpha[0].sum()\n",
    "                alpha[0] /= scale[0]\n",
    "                for t in range(1, T):\n",
    "                    alpha_t_prime = alpha[t-1].dot(self.A) * self.B[:, x[t]]\n",
    "                    scale[t] = alpha_t_prime.sum()\n",
    "                    alpha[t] = alpha_t_prime / scale[t]\n",
    "                logP[n] = np.log(scale).sum()\n",
    "                alphas.append(alpha)\n",
    "                scales.append(scale)\n",
    "\n",
    "                beta = np.zeros((T, self.M))\n",
    "                beta[-1] = 1\n",
    "                for t in range(T - 2, -1, -1):\n",
    "                    beta[t] = self.A.dot(self.B[:, x[t+1]] * beta[t+1]) / scale[t+1]\n",
    "                betas.append(beta)\n",
    "\n",
    "\n",
    "            cost = np.sum(logP)\n",
    "            costs.append(cost)\n",
    "\n",
    "            # now re-estimate pi, A, B\n",
    "            self.pi = np.sum((alphas[n][0] * betas[n][0]) for n in range(N)) / N\n",
    "\n",
    "            den1 = np.zeros((self.M, 1))\n",
    "            den2 = np.zeros((self.M, 1))\n",
    "            a_num = np.zeros((self.M, self.M))\n",
    "            b_num = np.zeros((self.M, V))\n",
    "            for n in range(N):\n",
    "                x = X[n]\n",
    "                T = len(x)\n",
    "                den1 += (alphas[n][:-1] * betas[n][:-1]).sum(axis=0, keepdims=True).T\n",
    "                den2 += (alphas[n] * betas[n]).sum(axis=0, keepdims=True).T\n",
    "\n",
    "                # numerator for A\n",
    "                # a_num_n = np.zeros((self.M, self.M))\n",
    "                for i in range(self.M):\n",
    "                    for j in range(self.M):\n",
    "                        for t in range(T-1):\n",
    "                            a_num[i,j] += alphas[n][t,i] * betas[n][t+1,j] * self.A[i,j] * self.B[j, x[t+1]] / scales[n][t+1]\n",
    "                # a_num += a_num_n\n",
    "\n",
    "                # numerator for B\n",
    "                # for i in range(self.M):\n",
    "                #     for j in range(V):\n",
    "                #         for t in range(T):\n",
    "                #             if x[t] == j:\n",
    "                #                 b_num[i,j] += alphas[n][t][i] * betas[n][t][i]\n",
    "                for i in range(self.M):\n",
    "                    for t in range(T):\n",
    "                        b_num[i,x[t]] += alphas[n][t,i] * betas[n][t,i]\n",
    "            self.A = a_num / den1\n",
    "            self.B = b_num / den2\n",
    "        print(\"A:\", self.A)\n",
    "        print(\"B:\", self.B)\n",
    "        print(\"pi:\", self.pi)\n",
    "\n",
    "        plt.plot(costs)\n",
    "        plt.show()\n",
    "\n",
    "    def log_likelihood(self, x):\n",
    "        # returns log P(x | model)\n",
    "        # using the forward part of the forward-backward algorithm\n",
    "        T = len(x)\n",
    "        scale = np.zeros(T)\n",
    "        alpha = np.zeros((T, self.M))\n",
    "        alpha[0] = self.pi*self.B[:,x[0]]\n",
    "        scale[0] = alpha[0].sum()\n",
    "        alpha[0] /= scale[0]\n",
    "        for t in range(1, T):\n",
    "            alpha_t_prime = alpha[t-1].dot(self.A) * self.B[:, x[t]]\n",
    "            scale[t] = alpha_t_prime.sum()\n",
    "            alpha[t] = alpha_t_prime / scale[t]\n",
    "        return np.log(scale).sum()\n",
    "\n",
    "    def log_likelihood_multi(self, X):\n",
    "        return np.array([self.log_likelihood(x) for x in X])\n",
    "\n",
    "    def get_state_sequence(self, x):\n",
    "        # returns the most likely state sequence given observed sequence x\n",
    "        # using the Viterbi algorithm\n",
    "        T = len(x)\n",
    "        delta = np.zeros((T, self.M))\n",
    "        psi = np.zeros((T, self.M))\n",
    "        delta[0] = np.log(self.pi) + np.log(self.B[:,x[0]])\n",
    "        for t in range(1, T):\n",
    "            for j in range(self.M):\n",
    "                delta[t,j] = np.max(delta[t-1] + np.log(self.A[:,j])) + np.log(self.B[j, x[t]])\n",
    "                psi[t,j] = np.argmax(delta[t-1] + np.log(self.A[:,j]))\n",
    "\n",
    "        # backtrack\n",
    "        states = np.zeros(T, dtype=np.int32)\n",
    "        states[T-1] = np.argmax(delta[T-1])\n",
    "        for t in range(T-2, -1, -1):\n",
    "            states[t] = psi[t+1, states[t+1]]\n",
    "        return states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T22:11:23.314893Z",
     "start_time": "2019-04-29T22:11:23.307798Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_coin():\n",
    "    X = []\n",
    "    for line in open('./data/coin_data.txt'):\n",
    "        # 1 for H, 0 for T\n",
    "        x = [1 if e == 'H' else 0 for e in line.rstrip()]\n",
    "        X.append(x)\n",
    "\n",
    "    hmm = HMM(2)\n",
    "    hmm.fit(X)\n",
    "    L = hmm.log_likelihood_multi(X).sum()\n",
    "    print(\"LL with fitted params:\", L)\n",
    "\n",
    "    # try true values\n",
    "    hmm.pi = np.array([0.5, 0.5])\n",
    "    hmm.A = np.array([[0.1, 0.9], [0.8, 0.2]])\n",
    "    hmm.B = np.array([[0.6, 0.4], [0.3, 0.7]])\n",
    "    L = hmm.log_likelihood_multi(X).sum()\n",
    "    print(\"LL with true params:\", L)\n",
    "\n",
    "    # try viterbi\n",
    "    print(\"Best state sequence for:\", X[0])\n",
    "    print(hmm.get_state_sequence(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T22:11:25.723599Z",
     "start_time": "2019-04-29T22:11:24.510272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial A: [[0.7087962  0.2912038 ]\n",
      " [0.29152056 0.70847944]]\n",
      "initial B: [[0.62969057 0.37030943]\n",
      " [0.58883752 0.41116248]]\n",
      "it: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marktblack/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:60: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it: 10\n",
      "it: 20\n",
      "A: [[0.70386662 0.29613338]\n",
      " [0.28712763 0.71287237]]\n",
      "B: [[0.54419694 0.45580306]\n",
      " [0.53723247 0.46276753]]\n",
      "pi: [0.50695647 0.49304353]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LL with fitted params: -1034.755754735206\n",
      "LL with true params: -1059.7229160265022\n",
      "Best state sequence for: [0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1]\n",
      "[0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    fit_coin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
