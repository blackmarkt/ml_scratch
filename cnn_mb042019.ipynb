{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN (Convolutional Neural Nets)\n",
    "\n",
    "- state of the art for image classification\n",
    "\n",
    "### Architecture\n",
    "\n",
    "1. `Convulational Layers` - image filters typically used with \"relu\" activation function\n",
    "\n",
    "2. `Pooling Layer` - reduces the image dimensions by \"pooling\" or combining multiple pixel regions into a window (i.e. \"maxpooling\" just takes the maximum value from that window)\n",
    "\n",
    "3. `Dense Layer` - perform classification on the features extracted by the convolutional layers and downsampled by the pooling layers. In a dense layer, every node in the layer is connected to every node in the preceding layer. \"connective tissue\"\n",
    "\n",
    "\n",
    "### Reference\n",
    "\n",
    "https://www.tensorflow.org/tutorials/estimators/cnn#intro_to_convolutional_neural_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T16:47:56.142775Z",
     "start_time": "2019-04-20T16:47:56.132086Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "NAME = \"Cats-v-Dog-cnn-62x2-{}\".format(int(time.time()))\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T16:47:57.675130Z",
     "start_time": "2019-04-20T16:47:57.659747Z"
    }
   },
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T16:49:38.234516Z",
     "start_time": "2019-04-20T16:49:38.012209Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle_in = open(\"./data/PetImages/X.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"./data/PetImages/y_pickle\", \"rb\")\n",
    "y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T17:09:12.757409Z",
     "start_time": "2019-04-20T17:09:12.753984Z"
    }
   },
   "outputs": [],
   "source": [
    "X = X[:30000]\n",
    "y = y[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T17:09:12.987696Z",
     "start_time": "2019-04-20T17:09:12.760345Z"
    }
   },
   "outputs": [],
   "source": [
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T17:11:03.262338Z",
     "start_time": "2019-04-20T17:09:12.990554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10500 samples, validate on 4500 samples\n",
      "Epoch 1/3\n",
      "10500/10500 [==============================] - 34s 3ms/sample - loss: 0.6934 - acc: 0.5040 - val_loss: 0.6931 - val_acc: 0.4998\n",
      "Epoch 2/3\n",
      "10500/10500 [==============================] - 37s 3ms/sample - loss: 0.6932 - acc: 0.4952 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 3/3\n",
      "10500/10500 [==============================] - 37s 4ms/sample - loss: 0.6932 - acc: 0.5019 - val_loss: 0.6932 - val_acc: 0.5002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14901aa20>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), input_shape=X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten()) # need to flatten before Dense\n",
    "# model.add(Dense(64))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, batch_size=32, epochs=3, validation_split=0.1, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing our CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T17:41:13.624906Z",
     "start_time": "2019-04-20T17:21:37.804020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-conf-32-nodes-0-dense-1555780897\n",
      "Train on 10500 samples, validate on 4500 samples\n",
      "Epoch 1/3\n",
      "10500/10500 [==============================] - 16s 2ms/sample - loss: 0.6934 - acc: 0.4990 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 2/3\n",
      "10500/10500 [==============================] - 15s 1ms/sample - loss: 0.6932 - acc: 0.4989 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 3/3\n",
      "10500/10500 [==============================] - 15s 1ms/sample - loss: 0.6932 - acc: 0.4983 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "2-conf-32-nodes-0-dense-1555780946\n",
      "Train on 10500 samples, validate on 4500 samples\n",
      "Epoch 1/3\n",
      "10500/10500 [==============================] - 34s 3ms/sample - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 2/3\n",
      "10500/10500 [==============================] - 35s 3ms/sample - loss: 0.6932 - acc: 0.5036 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 3/3\n",
      "10500/10500 [==============================] - 37s 3ms/sample - loss: 0.6931 - acc: 0.5036 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "3-conf-32-nodes-0-dense-1555781055\n",
      "Train on 10500 samples, validate on 4500 samples\n",
      "Epoch 1/3\n",
      "10500/10500 [==============================] - 43s 4ms/sample - loss: 0.6932 - acc: 0.5017 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 2/3\n",
      "10500/10500 [==============================] - 42s 4ms/sample - loss: 0.6932 - acc: 0.5006 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 3/3\n",
      "10500/10500 [==============================] - 41s 4ms/sample - loss: 0.6931 - acc: 0.5036 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "1-conf-64-nodes-0-dense-1555781184\n",
      "Train on 10500 samples, validate on 4500 samples\n",
      "Epoch 1/3\n",
      "10500/10500 [==============================] - 16s 2ms/sample - loss: 0.6932 - acc: 0.4996 - val_loss: 0.6931 - val_acc: 0.4998\n",
      "Epoch 2/3\n",
      "10500/10500 [==============================] - 15s 1ms/sample - loss: 0.6932 - acc: 0.5046 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 3/3\n",
      "10500/10500 [==============================] - 18s 2ms/sample - loss: 0.6932 - acc: 0.4981 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "2-conf-64-nodes-0-dense-1555781235\n",
      "Train on 10500 samples, validate on 4500 samples\n",
      "Epoch 1/3\n",
      "10500/10500 [==============================] - 36s 3ms/sample - loss: 0.6932 - acc: 0.4994 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 2/3\n",
      "10500/10500 [==============================] - 37s 3ms/sample - loss: 0.6932 - acc: 0.5023 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 3/3\n",
      "10500/10500 [==============================] - 36s 3ms/sample - loss: 0.6932 - acc: 0.4973 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "3-conf-64-nodes-0-dense-1555781348\n",
      "Train on 10500 samples, validate on 4500 samples\n",
      "Epoch 1/3\n",
      "10500/10500 [==============================] - 42s 4ms/sample - loss: 0.6932 - acc: 0.5034 - val_loss: 0.6931 - val_acc: 0.4998\n",
      "Epoch 2/3\n",
      "10500/10500 [==============================] - 43s 4ms/sample - loss: 0.6931 - acc: 0.5065 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 3/3\n",
      "10500/10500 [==============================] - 43s 4ms/sample - loss: 0.6932 - acc: 0.5036 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "1-conf-128-nodes-0-dense-1555781479\n",
      "Train on 10500 samples, validate on 4500 samples\n",
      "Epoch 1/3\n",
      "10500/10500 [==============================] - 16s 2ms/sample - loss: 0.6933 - acc: 0.5010 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 2/3\n",
      "10500/10500 [==============================] - 15s 1ms/sample - loss: 0.6931 - acc: 0.4981 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 3/3\n",
      "10500/10500 [==============================] - 16s 2ms/sample - loss: 0.6932 - acc: 0.5036 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "2-conf-128-nodes-0-dense-1555781529\n",
      "Train on 10500 samples, validate on 4500 samples\n",
      "Epoch 1/3\n",
      "10500/10500 [==============================] - 36s 3ms/sample - loss: 0.6932 - acc: 0.4992 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 2/3\n",
      "10500/10500 [==============================] - 37s 3ms/sample - loss: 0.6932 - acc: 0.5036 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 3/3\n",
      "10500/10500 [==============================] - 36s 3ms/sample - loss: 0.6932 - acc: 0.5036 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "3-conf-128-nodes-0-dense-1555781641\n",
      "Train on 10500 samples, validate on 4500 samples\n",
      "Epoch 1/3\n",
      "10500/10500 [==============================] - 43s 4ms/sample - loss: 0.6932 - acc: 0.5013 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 2/3\n",
      "10500/10500 [==============================] - 42s 4ms/sample - loss: 0.6932 - acc: 0.4970 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 3/3\n",
      "10500/10500 [==============================] - 43s 4ms/sample - loss: 0.6932 - acc: 0.5036 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "1-conf-32-nodes-1-dense-1555781773\n",
      "Train on 10500 samples, validate on 4500 samples\n",
      "Epoch 1/3\n",
      "10500/10500 [==============================] - 21s 2ms/sample - loss: 0.6932 - acc: 0.5027 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 2/3\n",
      "10500/10500 [==============================] - 19s 2ms/sample - loss: 0.6932 - acc: 0.4981 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 3/3\n",
      "10500/10500 [==============================] - 19s 2ms/sample - loss: 0.6932 - acc: 0.5036 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "2-conf-32-nodes-1-dense-1555781838\n",
      "Train on 10500 samples, validate on 4500 samples\n",
      "Epoch 1/3\n",
      "10500/10500 [==============================] - 37s 4ms/sample - loss: 0.6932 - acc: 0.4947 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 2/3\n",
      "10500/10500 [==============================] - 38s 4ms/sample - loss: 0.6932 - acc: 0.5036 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 3/3\n",
      "10500/10500 [==============================] - 39s 4ms/sample - loss: 0.6932 - acc: 0.5036 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "3-conf-32-nodes-1-dense-1555781956\n",
      "Train on 10500 samples, validate on 4500 samples\n",
      "Epoch 1/3\n",
      "10500/10500 [==============================] - 46s 4ms/sample - loss: 0.6932 - acc: 0.4956 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 2/3\n",
      "10500/10500 [==============================] - 41s 4ms/sample - loss: 0.6932 - acc: 0.5036 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 3/3\n",
      " 6592/10500 [=================>............] - ETA: 14s - loss: 0.6931 - acc: 0.5056"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-cdc6f897a35c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m                          metrics=['accuracy'])\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dense_layers = [0, 1, 2]\n",
    "layer_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2, 3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conf-{}-nodes-{}-dense-{}\".format(conv_layer,\n",
    "                                                        layer_size,\n",
    "                                                        dense_layer,\n",
    "                                                        int(time.time()))\n",
    "            print(NAME)\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(64, (3,3), input_shape=X.shape[1:]))\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "            for l in range(conv_layer-1):\n",
    "                model.add(Conv2D(64, (3,3)))\n",
    "                model.add(Activation(\"relu\"))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "            model.add(Flatten())\n",
    "            for l in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation(\"relu\"))\n",
    "            \n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "\n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                         optimizer='adam',\n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "            model.fit(X, y, batch_size=32, epochs=3, validation_split=0.3, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
